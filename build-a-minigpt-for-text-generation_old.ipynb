{"cells":[{"cell_type":"markdown","metadata":{},"source":["# ***WARNING*** \n","\n","## The data required to train the model for this task is known to be vulgar, offensive, toxic, racist, and otherwise not pleasant.\n","---"]},{"cell_type":"markdown","metadata":{},"source":["# MiniGPT For Generating Synthetic Text Data"]},{"cell_type":"markdown","metadata":{},"source":["## Problem Statement\n","\n","Toxic comments online come in many forms and in many arenas. There are currently several ways to mitigate these comments(for those organizations who wish to do so). Some of these ways include human moderators, and training machine learning models to detect toxicity in online comments.\n","\n","The issue with human moderators is that some of these platforms have grown so large so quickly that there are not nearly enough moderators to achieve any sense of control for most of these comments. The shear volume of toxicity and bots online makes it unrealistic to think we could do this job with humans at this point.\n","\n","Many companies are employing machine learning to assist with identifying toxic comments online automatically. The problem with this approach is the lack of labeled training data to train the models on.\n","\n","This is the problem I am going to solve using generative deep learning techniques. "]},{"cell_type":"markdown","metadata":{},"source":["## References\n","\n","* [Improving Language Understanding by Generative Pre-Training](https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035)\n","\n","* [Language Models are Unsupervised Multitask Learners](https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe)\n","\n","* [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n","\n","* Many of the ideas and code were adapted from this Keras resource: https://keras.io/examples/generative/text_generation_with_miniature_gpt/"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-26T18:35:51.939200Z","iopub.status.busy":"2023-06-26T18:35:51.938724Z","iopub.status.idle":"2023-06-26T18:35:51.947209Z","shell.execute_reply":"2023-06-26T18:35:51.946343Z","shell.execute_reply.started":"2023-06-26T18:35:51.939173Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n","  from pandas.core.computation.check import NUMEXPR_INSTALLED\n","[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /home/ubuntu/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}],"source":["import os\n","import string\n","import random\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import nltk\n","\n","from nltk import ngrams\n","from collections import Counter\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import TextVectorization\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","## set seeds for repeatable conclusion\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)"]},{"cell_type":"markdown","metadata":{},"source":["# Data\n","\n","The data I will be using to train the generative model was released on Kaggle as part of an ongoing series of competitions sponsored by the [Google company Jigsaw](https://en.wikipedia.org/wiki/Jigsaw_(company)).\n","\n","The data consists of online comments with various severity levels of toxicity. There are versions of these comments labeled by human annotators wherein they label each comment as toxic or not, or other sets where they were labeled as different categories of toxic such as hatespeech, racist/sexist, obscene, etc. Although these are the labeled datasets we would be adding the synthetic data to in order to create more training data, for this task of simply generating similar text data we will only focus on the comments themselves.\n","\n","The data provided by this competition includes a total of `14,251` unique toxic comments. Theses are the comments I will use to train the generative model with."]},{"cell_type":"markdown","metadata":{},"source":["# EDA\n","\n","The data came in two different files.\n","\n","1) Comments to score: This acts as a test dataset of comments for scoring after the model was trained.\n","\n","2) Validation data: This was the training data for the competition wherein there are two columns. One column labeled less toxic was a comment which human annotators labeled as less toxic than its more toxic counterpart in the other column. There was no actual training data where a comment was paired with its severity rating. The models were trained using creative techniques with the validation data and other classification data sets to train a model which predicted severity of comments.\n","\n","Since for our purposes we are only interested in the actual text comments themselves, I will only be using those columns from these datasources.\n","\n","I start by reading them all into pandas dataframes, isolating the text columns from each one, and stacking them all together so we have a single column of text when it is all said and done.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:35:51.949445Z","iopub.status.busy":"2023-06-26T18:35:51.948377Z","iopub.status.idle":"2023-06-26T18:35:52.022053Z","shell.execute_reply":"2023-06-26T18:35:52.020895Z","shell.execute_reply.started":"2023-06-26T18:35:51.949414Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7537 entries, 0 to 7536\n","Data columns (total 2 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   comment_id  7537 non-null   int64 \n"," 1   text        7537 non-null   object\n","dtypes: int64(1), object(1)\n","memory usage: 117.9+ KB\n"]},{"data":{"text/plain":["601                               silly little boy my ass\n","2031    Is that so? Than why so many people questiong ...\n","1928     Wow \\nThanks! You are SO amazing! I am in awe...\n","468     \"\\n\\n Send this to User:Bumpusmills1 \\n\\nPass ...\n","6351    \"\\n\\nthat is your opinion. And what is your pr...\n","748      man its all about captain morgans spiced rum....\n","Name: text, dtype: object"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["data1 = pd.read_csv('Jigsaw Rate Severity of Toxic Comments/comments_to_score.csv')\n","data1.info()\n","\n","## Isolate only text column\n","data1 = data1['text']\n","\n","data1.sample(6)"]},{"cell_type":"markdown","metadata":{},"source":["***We can see the comments to score was the test file which contained only comments and their corresponding id's***"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:35:52.023905Z","iopub.status.busy":"2023-06-26T18:35:52.023554Z","iopub.status.idle":"2023-06-26T18:35:52.250592Z","shell.execute_reply":"2023-06-26T18:35:52.249357Z","shell.execute_reply.started":"2023-06-26T18:35:52.023875Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 30108 entries, 0 to 30107\n","Data columns (total 3 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   worker      30108 non-null  int64 \n"," 1   less_toxic  30108 non-null  object\n"," 2   more_toxic  30108 non-null  object\n","dtypes: int64(1), object(2)\n","memory usage: 705.8+ KB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>worker</th>\n","      <th>less_toxic</th>\n","      <th>more_toxic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25318</th>\n","      <td>210</td>\n","      <td>F-U-C-K OFF SLANT EYE CHINK</td>\n","      <td>Anal sex \\n\\nI am gay and actively engage in ...</td>\n","    </tr>\n","    <tr>\n","      <th>208</th>\n","      <td>193</td>\n","      <td>\"\\n\\n Philip K. Dick \\n\\nHi, Ed.  You remove t...</td>\n","      <td>Adolf Shitler \\n\\nrecoment changing the title...</td>\n","    </tr>\n","    <tr>\n","      <th>14589</th>\n","      <td>277</td>\n","      <td>user:captain-poison*im sorry you thought Autop...</td>\n","      <td>Yes, and then what happened Sune?  It seems yo...</td>\n","    </tr>\n","    <tr>\n","      <th>6346</th>\n","      <td>246</td>\n","      <td>\"\\nBut the article doesn't even mention the wo...</td>\n","      <td>NO PISS OFF WIKIPEDIA, WHAT YOU GONNA DO ABOUT IT</td>\n","    </tr>\n","    <tr>\n","      <th>8922</th>\n","      <td>170</td>\n","      <td>I am going to sort you out \\n\\niz gonna track...</td>\n","      <td>Russians bring us Vodka???  What a stereotype...</td>\n","    </tr>\n","    <tr>\n","      <th>2519</th>\n","      <td>415</td>\n","      <td>Man, your civility puts me to shame. Don't be ...</td>\n","      <td>The Bleiburg Massacres took place over months ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       worker                                         less_toxic  \\\n","25318     210                        F-U-C-K OFF SLANT EYE CHINK   \n","208       193  \"\\n\\n Philip K. Dick \\n\\nHi, Ed.  You remove t...   \n","14589     277  user:captain-poison*im sorry you thought Autop...   \n","6346      246  \"\\nBut the article doesn't even mention the wo...   \n","8922      170   I am going to sort you out \\n\\niz gonna track...   \n","2519      415  Man, your civility puts me to shame. Don't be ...   \n","\n","                                              more_toxic  \n","25318   Anal sex \\n\\nI am gay and actively engage in ...  \n","208     Adolf Shitler \\n\\nrecoment changing the title...  \n","14589  Yes, and then what happened Sune?  It seems yo...  \n","6346   NO PISS OFF WIKIPEDIA, WHAT YOU GONNA DO ABOUT IT  \n","8922    Russians bring us Vodka???  What a stereotype...  \n","2519   The Bleiburg Massacres took place over months ...  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["data2 = pd.read_csv('Jigsaw Rate Severity of Toxic Comments/validation_data.csv')\n","data2.info()\n","\n","data2.sample(6)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:35:52.252939Z","iopub.status.busy":"2023-06-26T18:35:52.252518Z","iopub.status.idle":"2023-06-26T18:35:53.532254Z","shell.execute_reply":"2023-06-26T18:35:53.531429Z","shell.execute_reply.started":"2023-06-26T18:35:52.252902Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-24-f832a855ae14>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n","\n","\n","  data4 = pd.read_csv('Toxic comment/jigsaw-toxic-comment-train.csv',error_bad_lines=False, engine=\"python\")\n","Skipping line 191893: unexpected end of data\n"]},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 191891 entries, 0 to 191890\n","Data columns (total 8 columns):\n"," #   Column         Non-Null Count   Dtype \n","---  ------         --------------   ----- \n"," 0   id             191891 non-null  object\n"," 1   comment_text   191891 non-null  object\n"," 2   toxic          191891 non-null  int64 \n"," 3   severe_toxic   191891 non-null  int64 \n"," 4   obscene        191891 non-null  int64 \n"," 5   threat         191891 non-null  int64 \n"," 6   insult         191891 non-null  int64 \n"," 7   identity_hate  191891 non-null  int64 \n","dtypes: int64(6), object(2)\n","memory usage: 11.7+ MB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","      <th>sum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>16815</th>\n","      <td>2c59dd6870faa2e6</td>\n","      <td>Fuck you \\nFuck you racist basterd.</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>110134</th>\n","      <td>4d0d78b7bbf5dac8</td>\n","      <td>This guy is a huge fag \\n\\nTrue Story.</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>84728</th>\n","      <td>e2b40cf1f1190cf3</td>\n","      <td>YOU ARE FUCKING CALLING MY TALKING ON MY OWN F...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>56708</th>\n","      <td>978967242c15221f</td>\n","      <td>stop editing the truth that i posted in the MT...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>61362</th>\n","      <td>a44278c870a76373</td>\n","      <td>fuck you white trash!!!</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>118352</th>\n","      <td>78640b3baad0edbe</td>\n","      <td>Why is adrian such a f@cking loser??? GET A LIFE</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      id                                       comment_text  \\\n","16815   2c59dd6870faa2e6                Fuck you \\nFuck you racist basterd.   \n","110134  4d0d78b7bbf5dac8             This guy is a huge fag \\n\\nTrue Story.   \n","84728   e2b40cf1f1190cf3  YOU ARE FUCKING CALLING MY TALKING ON MY OWN F...   \n","56708   978967242c15221f  stop editing the truth that i posted in the MT...   \n","61362   a44278c870a76373                            fuck you white trash!!!   \n","118352  78640b3baad0edbe   Why is adrian such a f@cking loser??? GET A LIFE   \n","\n","        toxic  severe_toxic  obscene  threat  insult  identity_hate  sum  \n","16815       1             0        1       0       1              0    3  \n","110134      1             0        0       0       1              0    2  \n","84728       1             1        1       0       1              0    4  \n","56708       1             0        0       0       0              0    1  \n","61362       1             0        1       0       1              1    4  \n","118352      1             0        1       0       1              0    3  "]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["data4 = pd.read_csv('Toxic comment/jigsaw-toxic-comment-train.csv',error_bad_lines=False, engine=\"python\")\n","data4.info()\n","\n","## Sum across labels to filter out clean comments\n","data4['sum'] = data4.loc[:, 'toxic':].sum(axis=1)\n","\n","## Keep only comments with some type of label\n","data4 = data4[data4['sum'] > 0]\n","\n","data4.sample(6)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:35:53.534540Z","iopub.status.busy":"2023-06-26T18:35:53.534120Z","iopub.status.idle":"2023-06-26T18:36:06.042835Z","shell.execute_reply":"2023-06-26T18:36:06.041895Z","shell.execute_reply.started":"2023-06-26T18:35:53.534510Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 707301 entries, 0 to 707300\n","Data columns (total 34 columns):\n"," #   Column                               Non-Null Count   Dtype  \n","---  ------                               --------------   -----  \n"," 0   id                                   707301 non-null  int64  \n"," 1   comment_text                         707301 non-null  object \n"," 2   toxic                                707301 non-null  float64\n"," 3   severe_toxicity                      707301 non-null  float64\n"," 4   obscene                              707301 non-null  float64\n"," 5   identity_attack                      707301 non-null  float64\n"," 6   insult                               707301 non-null  float64\n"," 7   threat                               707301 non-null  float64\n"," 8   asian                                289784 non-null  float64\n"," 9   atheist                              289784 non-null  float64\n"," 10  bisexual                             289784 non-null  float64\n"," 11  black                                289784 non-null  float64\n"," 12  buddhist                             289784 non-null  float64\n"," 13  christian                            289784 non-null  float64\n"," 14  female                               289784 non-null  float64\n"," 15  heterosexual                         289784 non-null  float64\n"," 16  hindu                                289784 non-null  float64\n"," 17  homosexual_gay_or_lesbian            289784 non-null  float64\n"," 18  intellectual_or_learning_disability  289784 non-null  float64\n"," 19  jewish                               289784 non-null  float64\n"," 20  latino                               289784 non-null  float64\n"," 21  male                                 289784 non-null  float64\n"," 22  muslim                               289784 non-null  float64\n"," 23  other_disability                     289784 non-null  float64\n"," 24  other_gender                         289784 non-null  float64\n"," 25  other_race_or_ethnicity              289784 non-null  float64\n"," 26  other_religion                       289784 non-null  float64\n"," 27  other_sexual_orientation             289784 non-null  float64\n"," 28  physical_disability                  289784 non-null  float64\n"," 29  psychiatric_or_mental_illness        289784 non-null  float64\n"," 30  transgender                          289784 non-null  float64\n"," 31  white                                289784 non-null  float64\n"," 32  sexual_explicit                      707301 non-null  float64\n"," 33  sum                                  707301 non-null  float64\n","dtypes: float64(32), int64(1), object(1)\n","memory usage: 183.5+ MB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxicity</th>\n","      <th>obscene</th>\n","      <th>identity_attack</th>\n","      <th>insult</th>\n","      <th>threat</th>\n","      <th>asian</th>\n","      <th>atheist</th>\n","      <th>...</th>\n","      <th>other_gender</th>\n","      <th>other_race_or_ethnicity</th>\n","      <th>other_religion</th>\n","      <th>other_sexual_orientation</th>\n","      <th>physical_disability</th>\n","      <th>psychiatric_or_mental_illness</th>\n","      <th>transgender</th>\n","      <th>white</th>\n","      <th>sexual_explicit</th>\n","      <th>sum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>253190</th>\n","      <td>1076202</td>\n","      <td>I do not deny the spiritual. I deny YOUR visio...</td>\n","      <td>0.166667</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.266667</td>\n","    </tr>\n","    <tr>\n","      <th>101150</th>\n","      <td>588712</td>\n","      <td>Trudeau's &amp; Butts' brains must be stuck where ...</td>\n","      <td>0.400000</td>\n","      <td>0.0</td>\n","      <td>0.100000</td>\n","      <td>0.000000</td>\n","      <td>0.300000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.1</td>\n","      <td>1.800000</td>\n","    </tr>\n","    <tr>\n","      <th>655177</th>\n","      <td>6281667</td>\n","      <td>Foolish headline for the article! \\n\\nAs the a...</td>\n","      <td>0.400000</td>\n","      <td>0.0</td>\n","      <td>0.100000</td>\n","      <td>0.000000</td>\n","      <td>0.400000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>1.800000</td>\n","    </tr>\n","    <tr>\n","      <th>586057</th>\n","      <td>6060633</td>\n","      <td>It's always a winning strategy to blame the vi...</td>\n","      <td>0.200000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.300000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.3</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.800000</td>\n","    </tr>\n","    <tr>\n","      <th>244124</th>\n","      <td>1046359</td>\n","      <td>Where do people like you get these crazy ideas...</td>\n","      <td>0.166667</td>\n","      <td>0.0</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>360566</th>\n","      <td>5315708</td>\n","      <td>Congrats.  You have my vote.</td>\n","      <td>0.166667</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.666667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6 rows × 34 columns</p>\n","</div>"],"text/plain":["             id                                       comment_text     toxic  \\\n","253190  1076202  I do not deny the spiritual. I deny YOUR visio...  0.166667   \n","101150   588712  Trudeau's & Butts' brains must be stuck where ...  0.400000   \n","655177  6281667  Foolish headline for the article! \\n\\nAs the a...  0.400000   \n","586057  6060633  It's always a winning strategy to blame the vi...  0.200000   \n","244124  1046359  Where do people like you get these crazy ideas...  0.166667   \n","360566  5315708                       Congrats.  You have my vote.  0.166667   \n","\n","        severe_toxicity   obscene  identity_attack    insult  threat  asian  \\\n","253190              0.0  0.000000         0.000000  0.166667     0.0    0.0   \n","101150              0.0  0.100000         0.000000  0.300000     0.0    NaN   \n","655177              0.0  0.100000         0.000000  0.400000     0.0    NaN   \n","586057              0.0  0.000000         0.000000  0.300000     0.0    0.0   \n","244124              0.0  0.166667         0.000000  0.166667     0.0    NaN   \n","360566              0.0  0.000000         0.166667  0.000000     0.0    NaN   \n","\n","        atheist  ...  other_gender  other_race_or_ethnicity  other_religion  \\\n","253190      0.0  ...           0.0                      0.0             0.0   \n","101150      NaN  ...           NaN                      NaN             NaN   \n","655177      NaN  ...           NaN                      NaN             NaN   \n","586057      0.0  ...           0.0                      0.0             0.1   \n","244124      NaN  ...           NaN                      NaN             NaN   \n","360566      NaN  ...           NaN                      NaN             NaN   \n","\n","        other_sexual_orientation  physical_disability  \\\n","253190                       0.0                  0.0   \n","101150                       NaN                  NaN   \n","655177                       NaN                  NaN   \n","586057                       0.0                  0.0   \n","244124                       NaN                  NaN   \n","360566                       NaN                  NaN   \n","\n","        psychiatric_or_mental_illness  transgender  white  sexual_explicit  \\\n","253190                            0.0          0.0    0.0              0.0   \n","101150                            NaN          NaN    NaN              0.1   \n","655177                            NaN          NaN    NaN              0.0   \n","586057                            0.3          0.0    0.0              0.0   \n","244124                            NaN          NaN    NaN              0.0   \n","360566                            NaN          NaN    NaN              0.0   \n","\n","             sum  \n","253190  2.266667  \n","101150  1.800000  \n","655177  1.800000  \n","586057  1.800000  \n","244124  1.000000  \n","360566  0.666667  \n","\n","[6 rows x 34 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data5 = pd.read_csv('Toxic comment/jigsaw-unintended-bias-train.csv')\n","data5.info()\n","\n","# drop_columns = [\n","#     'created_date',\n","#     'publication_id',\n","#     'parent_id',\n","#     'article_id', \n","#     'rating', \n","#     'funny', \n","#     'wow', \n","#     'sad', \n","#     'likes', \n","#     'disagree', \n","#     'identity_annotator_count', \n","#     'toxicity_annotator_count'\n","# ]\n","\n","# data5 = data5.drop(columns=drop_columns, axis=0)\n","\n","## Sum across labels to filter out clean comments\n","data5['sum'] = data5.loc[:, 'toxic':].sum(axis=1)\n","\n","## Keep only comments with some type of label\n","data5 = data5[data5['sum'] > 0]\n","\n","data5.sample(6)"]},{"cell_type":"markdown","metadata":{},"source":["***This was the data provided to validate the models performance during training. The three columns are workers(annotators) and the other two are text columns which we will use both to train our generative model with.***"]},{"cell_type":"markdown","metadata":{},"source":["### Combine all columns into a single column"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.series.Series'>\n","Int64Index: 19361 entries, 6 to 191890\n","Series name: comment_text\n","Non-Null Count  Dtype \n","--------------  ----- \n","19361 non-null  object\n","dtypes: object(1)\n","memory usage: 302.5+ KB\n"]}],"source":["data4.info()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:36:06.044130Z","iopub.status.busy":"2023-06-26T18:36:06.043863Z","iopub.status.idle":"2023-06-26T18:36:06.282974Z","shell.execute_reply":"2023-06-26T18:36:06.281938Z","shell.execute_reply.started":"2023-06-26T18:36:06.044106Z"},"trusted":true},"outputs":[],"source":["## Isolate text column\n","data2 = data2['more_toxic']\n","data4 = data4['comment_text']\n","data5 = data5['comment_text']\n","\n","## Isolate text column\n","data3 = pd.read_csv('Jigsaw Rate Severity of Toxic Comments/validation_data.csv')\n","data3 = data3['less_toxic']\n","\n","text_column = pd.concat([data1, data2, data3, data4, data5], axis=0, ignore_index=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Check for duplicates"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:36:06.284556Z","iopub.status.busy":"2023-06-26T18:36:06.284248Z","iopub.status.idle":"2023-06-26T18:36:07.417058Z","shell.execute_reply":"2023-06-26T18:36:07.416420Z","shell.execute_reply.started":"2023-06-26T18:36:06.284532Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Nonsense.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              47\n","The domestic terrorists at the company called \"civil comments\" are attempting to destroy your first amendment right to free speech!\\nOnly in communist countries or in Nazi Germany you had to have approval of your speech by your peers!\\nThat's not the United States of America!\\nThat's Russia under the iron fist of a loser named Putin!\\nRESIST LOSING YOUR 1st Amendment right!\\nHere is the communists website I HOPE all hackers that are reading this understand it is time to take this website down are you listening @ \"anonymous\" our free-speech is being destroyed by these losers\\nBe a real American patriot like Thomas Jefferson and George Washington that fought for our first amendment rights for free speech !\\nhttps://www.getcivil.com    39\n","H.L. MENCKEN’S prediction:\\n\\n“As democracy is perfected, the office of the President represents, more and more closely, the inner soul of the people. On some great and glorious day, the plain folks of the Land will reach their heart’s desire at last, and the White House will be occupied by a downright fool and complete narcissist moron.”\\n\\n  -H.L. Mencken\\nThe Baltimore Evening Sun,\\nJuly 26, 1920                                                                                                                                                                                                                                                                                                                                                     34\n","Troll                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  25\n","How soon the failed Harpercons forget that Harper was the worst PM we ever had. Record deficits. Record debt. The worst fiscal record in 80 years. All Harper accomplished was adding $160 billion to the national debt plus a lot of corruption and electoral fraud.\\nOliver actually made a joke about having children to pay for Harper's debt.                                                                                                                                                                                                                                                                                                                                                                                                                     25\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ..\n","Keep trying to revise history and justify slavery, you racist bigot.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n","Good plan. Waste of all our time.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n","Fragedy!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n","No, I say that antsemitic, racist, and homophobic speech is hate speech. That's the sort of speech that Milo spews. And, apparently, that's the sort of speech you support. \\n\\nAs a Christian and a human being -- heck, as a carbon-based lifeform -- I believe that such speech should not be allowed on the public forum. Hatred is not something to be encouraged.\\n\\nYou would encourage him in jis hatred. You are a Trump supporter. \\n\\nOh and your LIE that I support mob violence is something you should be ashamed of. But rhen, Trump supporters also support lying, since your glorious leader is such an inveterate liar.                                                                                                                               1\n","I hope you millennials are happy that you put this airhead in charge.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n","Length: 732508, dtype: int64"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["text_column.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["It looks like between the data provided for the competition there are many duplicates. However we can see that some comments are reused many more times than other comments. For example the most used comments were repeated `19` times in the datasets while others only `2` times. \n","\n","Since the duplications are not balanced if we left the data like this I am afraid we would be biasing the model towards the comments which were present more in the data. \n","\n","I will remove all duplicate comments."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:36:07.419599Z","iopub.status.busy":"2023-06-26T18:36:07.418142Z","iopub.status.idle":"2023-06-26T18:36:08.628694Z","shell.execute_reply":"2023-06-26T18:36:08.627170Z","shell.execute_reply.started":"2023-06-26T18:36:07.419565Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total numer of comments in text data = 794415\n","Numer of unique comments in text data = 732508\n","Duplicate comments dropped\n"]}],"source":["print(f\"Total numer of comments in text data = {len(text_column)}\")\n","print(f\"Numer of unique comments in text data = {len(text_column.unique())}\")\n","\n","text_column = text_column.drop_duplicates()\n","print(\"Duplicate comments dropped\")"]},{"cell_type":"markdown","metadata":{},"source":["### Exploring the toxic comments"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:36:08.630459Z","iopub.status.busy":"2023-06-26T18:36:08.630133Z","iopub.status.idle":"2023-06-26T18:36:09.494845Z","shell.execute_reply":"2023-06-26T18:36:09.494019Z","shell.execute_reply.started":"2023-06-26T18:36:08.630435Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word_count</th>\n","      <th>verb_count</th>\n","      <th>noun_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>100.000000</td>\n","      <td>100.000000</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>66.340000</td>\n","      <td>11.220000</td>\n","      <td>15.680000</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>54.079668</td>\n","      <td>9.814008</td>\n","      <td>13.079307</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>5.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>23.750000</td>\n","      <td>3.000000</td>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>50.500000</td>\n","      <td>8.500000</td>\n","      <td>12.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>92.250000</td>\n","      <td>17.000000</td>\n","      <td>22.500000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>210.000000</td>\n","      <td>39.000000</td>\n","      <td>51.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       word_count  verb_count  noun_count\n","count  100.000000  100.000000  100.000000\n","mean    66.340000   11.220000   15.680000\n","std     54.079668    9.814008   13.079307\n","min      5.000000    0.000000    1.000000\n","25%     23.750000    3.000000    5.000000\n","50%     50.500000    8.500000   12.000000\n","75%     92.250000   17.000000   22.500000\n","max    210.000000   39.000000   51.000000"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.DataFrame()\n","data['text'] = text_column\n","data = data.sample(100)\n","\n","# Function to calculate word count\n","def count_words(text):\n","    words = nltk.word_tokenize(text)\n","    return len(words)\n","\n","# Function to calculate verb count\n","def count_verbs(text):\n","    words = nltk.word_tokenize(text)\n","    tagged_words = nltk.pos_tag(words)\n","    verb_count = len([word for word, tag in tagged_words if tag.startswith('V')])\n","    return verb_count\n","\n","# Function to calculate noun count\n","def count_nouns(text):\n","    words = nltk.word_tokenize(text)\n","    tagged_words = nltk.pos_tag(words)\n","    noun_count = len([word for word, tag in tagged_words if tag.startswith('N')])\n","    return noun_count\n","\n","# Add word count column\n","data['word_count'] = data['text'].apply(count_words)\n","\n","# Add verb count column\n","data['verb_count'] = data['text'].apply(count_verbs)\n","\n","# Add noun count column\n","data['noun_count'] = data['text'].apply(count_nouns)\n","\n","data.describe()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:36:09.496124Z","iopub.status.busy":"2023-06-26T18:36:09.495876Z","iopub.status.idle":"2023-06-26T18:36:09.801191Z","shell.execute_reply":"2023-06-26T18:36:09.799725Z","shell.execute_reply.started":"2023-06-26T18:36:09.496103Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["ax = data['word_count'].plot(kind='kde')\n","data['verb_count'].plot(kind='kde', ax=ax)\n","data['noun_count'].plot(kind='kde', ax=ax)\n","\n","ax.legend(['Word Count', 'Verb Count', 'Noun Count'])\n","ax.set_title('Distribution of Word Count, Verb Count, and Noun Count')\n","ax.set_xlabel('Count')\n","ax.set_ylabel('Density')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We can see that these comments on average are quite short in length and contain more nouns than verbs on average.\n","\n","Since we have not done any cleaning of the data yet these distributions are not exact as the nltk package is not currently looking for misspelled words or different versions of word spellings which are used online sometimes.\n","\n","For example if a user knows that the platform they are on has limitations on language than they may spell a profane word to try to fool any auto detecting systems such as `Fuck==>Fxck, F*ck, Fukk, Fuuu*uukk`, etc.\n","\n","Therefore these counts will not detect all nouns and verbs but should give a decent sample.\n","\n","Knowing the underlying distributions of some of these features is important because after the synthetic data is generated we would most likely want it to follow the same distributions for these attributes of the text. "]},{"cell_type":"markdown","metadata":{},"source":["### Looking at the most common N-grams"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:36:09.802723Z","iopub.status.busy":"2023-06-26T18:36:09.802424Z","iopub.status.idle":"2023-06-26T18:36:09.936877Z","shell.execute_reply":"2023-06-26T18:36:09.935778Z","shell.execute_reply.started":"2023-06-26T18:36:09.802695Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bigrams</th>\n","      <th>trigrams</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>((of, the), 25)</td>\n","      <td>((!, !, !), 6)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>((., I), 17)</td>\n","      <td>((., This, is), 5)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>((in, the), 16)</td>\n","      <td>((I, do, n't), 5)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>((do, n't), 15)</td>\n","      <td>((*, *, *), 5)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>((., The), 15)</td>\n","      <td>((., It, 's), 4)</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>((to, be), 15)</td>\n","      <td>((--, --, --), 4)</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>((!, !), 14)</td>\n","      <td>((the, United, States), 4)</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>((is, a), 13)</td>\n","      <td>((and, should, not), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>((that, the), 12)</td>\n","      <td>((is, not, a), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>((., It), 10)</td>\n","      <td>((they, do, n't), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>((and, the), 10)</td>\n","      <td>((n't, have, to), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>((,, and), 10)</td>\n","      <td>((,, I, am), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>((,, the), 9)</td>\n","      <td>((do, n't, know), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>((., This), 9)</td>\n","      <td>((is, going, to), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>((is, not), 9)</td>\n","      <td>((you, do, n't), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>((to, the), 9)</td>\n","      <td>((Happy, days, are), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>((It, 's), 8)</td>\n","      <td>((days, are, here), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>((., If), 8)</td>\n","      <td>((are, here, again), 3)</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>((their, own), 8)</td>\n","      <td>((to, do, with), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>((,, I), 8)</td>\n","      <td>((and, it, is), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>((to, do), 7)</td>\n","      <td>((wrong, with, this), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>((it, is), 7)</td>\n","      <td>((This, is, an), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>((., They), 7)</td>\n","      <td>((., If, the), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>((the, same), 7)</td>\n","      <td>((There, is, a), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>((by, the), 7)</td>\n","      <td>((health, care, ,), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>((is, the), 7)</td>\n","      <td>((except, for, those), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>((I, do), 7)</td>\n","      <td>((the, private, sector), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>((,, but), 7)</td>\n","      <td>((., We, have), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>((as, the), 6)</td>\n","      <td>((to, the, front), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>((This, is), 6)</td>\n","      <td>((the, front, door), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>((going, to), 6)</td>\n","      <td>((would, have, been), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>((it, .), 6)</td>\n","      <td>((this, is, not), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>((., He), 6)</td>\n","      <td>((sides, of, the), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>((on, the), 6)</td>\n","      <td>((of, the, political), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>((can, not), 6)</td>\n","      <td>((the, political, spectrum), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>((want, to), 6)</td>\n","      <td>((to, be, a), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>((--, --), 6)</td>\n","      <td>((over, and, over), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>((did, not), 6)</td>\n","      <td>((., I, do), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>((I, 'm), 6)</td>\n","      <td>((do, n't, even), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>((*, *), 6)</td>\n","      <td>((that, she, was), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>((must, be), 5)</td>\n","      <td>((., I, am), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>((for, the), 5)</td>\n","      <td>((and, I, do), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>((in, a), 5)</td>\n","      <td>((I, do, not), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>((was, a), 5)</td>\n","      <td>((because, it, is), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>((and, it), 5)</td>\n","      <td>((is, a, whole), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>((are, not), 5)</td>\n","      <td>((., There, is), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>((not, the), 5)</td>\n","      <td>((those, in, the), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>((It, is), 5)</td>\n","      <td>((A, lot, of), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>((them, .), 5)</td>\n","      <td>((around, the, world), 2)</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>((health, care), 5)</td>\n","      <td>((25, years, ago), 2)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                bigrams                         trigrams\n","0       ((of, the), 25)                   ((!, !, !), 6)\n","1          ((., I), 17)               ((., This, is), 5)\n","2       ((in, the), 16)                ((I, do, n't), 5)\n","3       ((do, n't), 15)                   ((*, *, *), 5)\n","4        ((., The), 15)                 ((., It, 's), 4)\n","5        ((to, be), 15)                ((--, --, --), 4)\n","6          ((!, !), 14)       ((the, United, States), 4)\n","7         ((is, a), 13)          ((and, should, not), 3)\n","8     ((that, the), 12)                ((is, not, a), 3)\n","9         ((., It), 10)             ((they, do, n't), 3)\n","10     ((and, the), 10)             ((n't, have, to), 3)\n","11       ((,, and), 10)                  ((,, I, am), 3)\n","12        ((,, the), 9)             ((do, n't, know), 3)\n","13       ((., This), 9)             ((is, going, to), 3)\n","14       ((is, not), 9)              ((you, do, n't), 3)\n","15       ((to, the), 9)          ((Happy, days, are), 3)\n","16        ((It, 's), 8)           ((days, are, here), 3)\n","17         ((., If), 8)          ((are, here, again), 3)\n","18    ((their, own), 8)              ((to, do, with), 2)\n","19          ((,, I), 8)               ((and, it, is), 2)\n","20        ((to, do), 7)         ((wrong, with, this), 2)\n","21        ((it, is), 7)              ((This, is, an), 2)\n","22       ((., They), 7)                ((., If, the), 2)\n","23     ((the, same), 7)              ((There, is, a), 2)\n","24       ((by, the), 7)           ((health, care, ,), 2)\n","25       ((is, the), 7)        ((except, for, those), 2)\n","26         ((I, do), 7)      ((the, private, sector), 2)\n","27        ((,, but), 7)               ((., We, have), 2)\n","28       ((as, the), 6)            ((to, the, front), 2)\n","29      ((This, is), 6)          ((the, front, door), 2)\n","30     ((going, to), 6)         ((would, have, been), 2)\n","31         ((it, .), 6)             ((this, is, not), 2)\n","32         ((., He), 6)            ((sides, of, the), 2)\n","33       ((on, the), 6)        ((of, the, political), 2)\n","34      ((can, not), 6)  ((the, political, spectrum), 2)\n","35      ((want, to), 6)                 ((to, be, a), 2)\n","36        ((--, --), 6)           ((over, and, over), 2)\n","37      ((did, not), 6)                  ((., I, do), 2)\n","38         ((I, 'm), 6)             ((do, n't, even), 2)\n","39          ((*, *), 6)            ((that, she, was), 2)\n","40      ((must, be), 5)                  ((., I, am), 2)\n","41      ((for, the), 5)                ((and, I, do), 2)\n","42         ((in, a), 5)                ((I, do, not), 2)\n","43        ((was, a), 5)           ((because, it, is), 2)\n","44       ((and, it), 5)              ((is, a, whole), 2)\n","45      ((are, not), 5)              ((., There, is), 2)\n","46      ((not, the), 5)            ((those, in, the), 2)\n","47        ((It, is), 5)                ((A, lot, of), 2)\n","48       ((them, .), 5)        ((around, the, world), 2)\n","49  ((health, care), 5)            ((25, years, ago), 2)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Tokenize the text into words\n","data['words'] = data['text'].apply(nltk.word_tokenize)\n","\n","# Get bigrams and trigrams for each row\n","data['bigrams']   = data['words'].apply(lambda x: list(ngrams(x, 2)))\n","data['trigrams']  = data['words'].apply(lambda x: list(ngrams(x, 3)))\n","# data['quadgrams'] = data['words'].apply(lambda x: list(ngrams(x, 4)))\n","\n","# Count the occurrences of bigrams and trigrams\n","bigram_counts   = Counter([gram for grams in data['bigrams'] for gram in grams])\n","trigram_counts  = Counter([gram for grams in data['trigrams'] for gram in grams])\n","# quadgram_counts = Counter([gram for grams in data['quadgrams'] for gram in grams])\n","\n","# Get the most common bigrams, trigrams, and quadgrams\n","most_common_bigrams   = bigram_counts.most_common(50)\n","most_common_trigrams  = trigram_counts.most_common(50)\n","# most_common_quadgrams = quadgram_counts.most_common(50)\n","\n","df_common_grams = pd.DataFrame()\n","df_common_grams['bigrams']   = most_common_bigrams\n","df_common_grams['trigrams']  = most_common_trigrams\n","# df_common_grams['quadgrams'] = most_common_quadgrams\n","\n","# # Display the results\n","# print('Most common bigrams:')\n","# for bigram, count in most_common_bigrams:\n","#     print(' '.join(bigram), count)\n","\n","# print('\\nMost common trigrams:')\n","# for trigram, count in most_common_trigrams:\n","#     print(' '.join(trigram), count)\n","    \n","# print('\\nMost common quadgrams:')\n","# for quadgram, count in most_common_quadgrams:\n","#     print(' '.join(quadgram), count)\n","\n","\n","df_common_grams.iloc[:, :]"]},{"cell_type":"markdown","metadata":{},"source":["We can see the initial 10 or so most common bi-grams and tri-grams are repetitive punctuation marks.\n","\n","Traditionally these would be cleaned and removed when training models for NLP tasks, however due to the nature of this work many of these traditional techniques will limit the models ability to predict toxicity as well as with clean text.\n","\n","I happened to have competed in this competition and one thing all of us learned was that leaving capital letters and punctuation improved the models ability to infer toxicity and especially levels of toxicity. \n","\n","For example a phrase such as:\n","\n","`Are you kidding?`\n","\n","Conveys a much different meaning than the same words but put this way:\n","\n","`ARE YOU KIDDING!!!??`\n","\n","Traditional NLP techniques would have us convert all characters to lower case and remove punctuation so the model will interpret both of those texts the exact same way.\n","\n","When training sentiment based models or models where feeling and emotion is being conveyed in some way such as toxicity of comments, it is more than just the raw content of the words alone which gives the meaning. The puncuation and capitalizations are very expressive forms of language and as such for these problems do better left in the data."]},{"cell_type":"markdown","metadata":{},"source":["## Pre-Processing\n","\n","* First we need load in our text column as tensorflow formatted dataset\n","\n","* Next we shuffle the data to avoid any patterns which may have been present\n","\n","* We then slice the data into batches for processing\n","\n","* Vectorize the text which will be used to create a corpus of vocabulary used when training and act as vector representations of our text\n","\n","* Create the corpus of vocabulary which is used to train and evaluate throughout"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:36:09.938657Z","iopub.status.busy":"2023-06-26T18:36:09.938032Z","iopub.status.idle":"2023-06-26T18:36:33.266746Z","shell.execute_reply":"2023-06-26T18:36:33.265630Z","shell.execute_reply.started":"2023-06-26T18:36:09.938625Z"},"trusted":true},"outputs":[],"source":["vocab_size = 100000  ## Only consider the top 20k words\n","maxlen = 80  ## Max sequence length\n","batch_size = 128  ## Data loading batch sizes\n","\n","# Create a dataset from the pandas column\n","text_ds = tf.data.Dataset.from_tensor_slices(text_column)\n","\n","# Shuffle and batch the dataset\n","text_ds = text_ds.shuffle(buffer_size=128)\n","text_ds = text_ds.batch(batch_size)\n","\n","# def custom_standardization(input_string):\n","#     \"\"\" Remove html line-break tags and handle punctuation \"\"\"\n","#     lowercased = tf.strings.lower(input_string)\n","#     stripped_html = tf.strings.regex_replace(lowercased, \"<br />\", \" \")\n","#     return tf.strings.regex_replace(stripped_html, f\"([{string.punctuation}])\", r\" \\1\")\n","\n","\n","## Create a vectorization layer and adapt it to the text\n","vectorize_layer = TextVectorization(\n","    standardize=None,\n","    max_tokens=vocab_size - 1,\n","    output_mode=\"int\",\n","    output_sequence_length=maxlen + 1,\n",")\n","vectorize_layer.adapt(text_ds)\n","vocab = vectorize_layer.get_vocabulary()  ## To get words back from token indices"]},{"cell_type":"markdown","metadata":{},"source":["## Generate Labels\n","\n","Since we are building a generative auto-regressive model, we must train it to predict the next word by looking backwards and using the previous tokens to predict the highest probability for the next token.\n","\n","This is fairly easy to create labels for because we simply shuffle the `TRUE` data be one token and then when training the model compares the predicted text with the next indexed word.\n","\n","We can inspect what these samples and labels look like below:"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:36:33.268256Z","iopub.status.busy":"2023-06-26T18:36:33.267986Z","iopub.status.idle":"2023-06-26T18:36:33.325428Z","shell.execute_reply":"2023-06-26T18:36:33.324346Z","shell.execute_reply.started":"2023-06-26T18:36:33.268234Z"},"trusted":true},"outputs":[],"source":["## Function to create target column\n","def prepare_lm_inputs_labels(text):\n","    \"\"\"\n","    Shift word sequences by 1 position so that the target for position (i) is\n","    word at position (i+1). The model will use all words up till position (i)\n","    to predict the next word.\n","    \"\"\"\n","    text = tf.expand_dims(text, -1)\n","    tokenized_sentences = vectorize_layer(text)\n","    x = tokenized_sentences[:, :-1]\n","    y = tokenized_sentences[:, 1:]\n","    return x, y\n","\n","\n","text_ds = text_ds.map(prepare_lm_inputs_labels)\n","text_ds = text_ds.prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T18:36:33.327226Z","iopub.status.busy":"2023-06-26T18:36:33.326828Z","iopub.status.idle":"2023-06-26T18:36:33.551883Z","shell.execute_reply":"2023-06-26T18:36:33.550424Z","shell.execute_reply.started":"2023-06-26T18:36:33.327195Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\n","\n","Input Sequence:\n","\" I already gave you the source for all my edits The [UNK] [UNK] so I will not continue to play your little game. If you weren't so lazy and intent on harassment, you could use Google to search for [UNK] and [UNK] You get more than 400 hits including white supremacist sites and an academic paper dating to 1996. It's obviously a real slur with some usage. Nice try at being [UNK] though. I'm sure there's a slur that\n","\n","Target Sequence:\n","I already gave you the source for all my edits The [UNK] [UNK] so I will not continue to play your little game. If you weren't so lazy and intent on harassment, you could use Google to search for [UNK] and [UNK] You get more than 400 hits including white supremacist sites and an academic paper dating to 1996. It's obviously a real slur with some usage. Nice try at being [UNK] though. I'm sure there's a slur that describes\n","\n","\n","\n","\n","Input Sequence:\n","\" I'd say [UNK] [UNK] is not heavy metal but hard rock, although since there are no good Croatian heavy metal bands it's not an important mistake. In my opinion, they are really fucking great. The songs [UNK] [UNK] [UNK] [UNK] and [UNK] are my [UNK] \"                                 \n","\n","Target Sequence:\n","I'd say [UNK] [UNK] is not heavy metal but hard rock, although since there are no good Croatian heavy metal bands it's not an important mistake. In my opinion, they are really fucking great. The songs [UNK] [UNK] [UNK] [UNK] and [UNK] are my [UNK] \"                                  \n","\n","\n","\n","\n","Input Sequence:\n","3RR RULE That's FOUR for you today already at Saudi Arabia, [UNK] I'm assuming good faith and not going to report you on it yet. Knock it off.                                                    \n","\n","Target Sequence:\n","RULE That's FOUR for you today already at Saudi Arabia, [UNK] I'm assuming good faith and not going to report you on it yet. Knock it off.                                                     \n","\n","\n","\n","\n","Input Sequence:\n","I confess to having complete (and apparently [UNK] ignorance of Jordan, but I've glanced at the article. Is this a woman or a soap [UNK] I don't think there was much to change in terms of the description of the various diseases. It is mentioned that she is famous for the size of her [UNK] am I correct in assuming this is because they are grotesquely large rather than vanishingly small? [UNK] 11 Jul 2003 (UTC)    \n","\n","Target Sequence:\n","confess to having complete (and apparently [UNK] ignorance of Jordan, but I've glanced at the article. Is this a woman or a soap [UNK] I don't think there was much to change in terms of the description of the various diseases. It is mentioned that she is famous for the size of her [UNK] am I correct in assuming this is because they are grotesquely large rather than vanishingly small? [UNK] 11 Jul 2003 (UTC)     \n","\n","\n","\n","\n","Input Sequence:\n","Please just let us know what you found. I'm not asking for details. Just let u know if the same IP address was used or what ever else you found that caused you to [UNK] that he was [UNK] sockpuppets. No details, jsut what was it? I am one of [UNK] most hated enemies, so I think I'm the perfect person to ask this. Vandalism from an IP address used by [UNK] was revealed using checkuser adn he was able\n","\n","Target Sequence:\n","just let us know what you found. I'm not asking for details. Just let u know if the same IP address was used or what ever else you found that caused you to [UNK] that he was [UNK] sockpuppets. No details, jsut what was it? I am one of [UNK] most hated enemies, so I think I'm the perfect person to ask this. Vandalism from an IP address used by [UNK] was revealed using checkuser adn he was able to\n"]}],"source":["## Select samples from the training data set to inspect\n","sample = text_ds.take(5) \n","\n","## Display some samples\n","for x, y in sample:\n","    # Convert token indices back to words\n","    input_words  = [vocab[i] for i in x[0].numpy()]\n","    target_words = [vocab[i] for i in y[0].numpy()]\n","\n","    print(\"\\n\\n\\n\\nInput Sequence:\")\n","    print(\" \".join(input_words))\n","    print(\"\\nTarget Sequence:\")\n","    print(\" \".join(target_words))"]},{"cell_type":"markdown","metadata":{},"source":["* ***We can see that the target or label sequence is merely our ground truth text sequence we have just shifted by `1` token. This is what our model will use to evaluate during training.***\n","\n","* ***Cell below was for loading in and preprocessing the IMBD movie quotes dataset. This is the dataset I tested this approach on first.***"]},{"cell_type":"markdown","metadata":{},"source":["# Build Model"]},{"cell_type":"markdown","metadata":{},"source":["## Implement the Transformer Block and Attention Head"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T17:20:05.315418Z","iopub.status.busy":"2023-06-26T17:20:05.314777Z","iopub.status.idle":"2023-06-26T17:20:05.334841Z","shell.execute_reply":"2023-06-26T17:20:05.333143Z","shell.execute_reply.started":"2023-06-26T17:20:05.315387Z"},"trusted":true},"outputs":[],"source":["def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n","    \"\"\"\n","    Creates a mask for causal (auto-regressive) self-attention. The returned mask has the shape \n","    [batch_size, n_dest, n_src], where each entry at position (i, j, k) will be 1 if j >= k and 0 otherwise. \n","    This is used to prevent the attention mechanism from attending to future positions during the forward pass.\n","\n","    Args:\n","        batch_size (int): Number of sequences in each batch.\n","        n_dest (int): Number of destination attention heads.\n","        n_src (int): Number of source attention heads.\n","        dtype (tf.DType): Type of the output tensor.\n","\n","    Returns:\n","        tf.Tensor: A tensor of shape [batch_size, n_dest, n_src] representing the mask.\n","    \"\"\"\n","\n","    # Create two range tensors i and j, where i has shape [n_dest, 1] and j has shape [n_src]\n","    i = tf.range(n_dest)[:, None]\n","    j = tf.range(n_src)\n","\n","    # Create a mask where entry (i, j) is True if i >= j - n_src + n_dest and False otherwise\n","    m = i >= j - n_src + n_dest\n","\n","    # Cast the mask to the desired data type\n","    mask = tf.cast(m, dtype)\n","\n","    # Reshape the mask to have shape [1, n_dest, n_src]\n","    mask = tf.reshape(mask, [1, n_dest, n_src])\n","\n","    # Create a tensor with shape [2] that represents the multiples for tiling\n","    mult = tf.concat(\n","        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n","    )\n","\n","    # Tile the mask tensor to have shape [batch_size, n_dest, n_src]\n","    return tf.tile(mask, mult)\n","\n","\n","\n","class TransformerBlock(layers.Layer):\n","    \"\"\"\n","    A Transformer block that includes multi-head self-attention and a feed-forward neural network.\n","    Each of these two components has a residual connection and is followed by layer normalization.\n","\n","    Attributes:\n","        att (layers.MultiHeadAttention): Multi-head self-attention layer.\n","        ffn (keras.Sequential): Feed-forward neural network.\n","        layernorm1 (layers.LayerNormalization): Layer normalization after the self-attention.\n","        layernorm2 (layers.LayerNormalization): Layer normalization after the feed-forward network.\n","        dropout1 (layers.Dropout): Dropout layer after the self-attention.\n","        dropout2 (layers.Dropout): Dropout layer after the feed-forward network.\n","    \"\"\"\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        \"\"\"\n","        Initializes the Transformer block.\n","\n","        Args:\n","            embed_dim (int): Dimensionality of the input embeddings.\n","            num_heads (int): Number of attention heads.\n","            ff_dim (int): Number of units in the hidden layer of the feed-forward network.\n","            rate (float): Dropout rate.\n","        \"\"\"\n","        super().__init__()\n","        self.att = layers.MultiHeadAttention(num_heads, embed_dim)\n","        self.ffn = keras.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs):\n","        \"\"\"\n","        Forward pass of the Transformer block.\n","\n","        Args:\n","            inputs (tf.Tensor): Input tensor of shape [batch_size, seq_len, embed_dim].\n","\n","        Returns:\n","            tf.Tensor: Output tensor of shape [batch_size, seq_len, embed_dim].\n","        \"\"\"\n","        # Compute the shapes\n","        input_shape = tf.shape(inputs)\n","        batch_size = input_shape[0]\n","        seq_len = input_shape[1]\n","\n","        # Create the causal mask for the multi-head self-attention\n","        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n","\n","        # Compute the output of the multi-head self-attention\n","        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n","\n","        # Apply dropout to the attention output\n","        attention_output = self.dropout1(attention_output)\n","\n","        # Add the attention output to the inputs (residual connection) and normalize the result\n","        out1 = self.layernorm1(inputs + attention_output)\n","\n","        # Compute the output of the feed-forward network\n","        ffn_output = self.ffn(out1)\n","\n","        # Apply dropout to the feed-forward output\n","        ffn_output = self.dropout2(ffn_output)\n","\n","        # Add the feed-forward output to the previous output (residual connection) and normalize the result\n","        return self.layernorm2(out1 + ffn_output)"]},{"cell_type":"markdown","metadata":{},"source":["## Implement Embedding layer\n","\n","***Create two separate embedding layers:***\n","\n","1) One for tokens \n","\n","2) One for token indices(positions)."]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T17:20:05.341168Z","iopub.status.busy":"2023-06-26T17:20:05.338621Z","iopub.status.idle":"2023-06-26T17:20:05.351657Z","shell.execute_reply":"2023-06-26T17:20:05.350812Z","shell.execute_reply.started":"2023-06-26T17:20:05.341136Z"},"trusted":true},"outputs":[],"source":["class TokenAndPositionEmbedding(layers.Layer):\n","    \"\"\"\n","    Layer for combining token and positional embeddings. Token embeddings provide the model\n","    with understanding of the meaning of each token, while positional embeddings provide\n","    information about the position of each token in the sequence.\n","\n","    Attributes:\n","        token_emb (layers.Embedding): Token embedding layer.\n","        pos_emb (layers.Embedding): Position embedding layer.\n","    \"\"\"\n","    def __init__(self, maxlen, vocab_size, embed_dim):\n","        \"\"\"\n","        Initializes the TokenAndPositionEmbedding layer.\n","\n","        Args:\n","            maxlen (int): Maximum length of the sequences for positional encoding.\n","            vocab_size (int): Size of the vocabulary for token encoding.\n","            embed_dim (int): Dimensionality of the output embeddings.\n","        \"\"\"\n","        super().__init__()\n","        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n","\n","    def call(self, x):\n","        \"\"\"\n","        Forward pass of the TokenAndPositionEmbedding layer.\n","\n","        Args:\n","            x (tf.Tensor): Input tensor of shape [batch_size, seq_len].\n","\n","        Returns:\n","            tf.Tensor: Output tensor of shape [batch_size, seq_len, embed_dim], resulting from\n","            adding token embeddings and position embeddings.\n","        \"\"\"\n","        # Compute the maximum sequence length\n","        maxlen = tf.shape(x)[-1]\n","\n","        # Create a range tensor representing positions\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\n","\n","        # Compute the position embeddings\n","        positions = self.pos_emb(positions)\n","\n","        # Compute the token embeddings\n","        x = self.token_emb(x)\n","\n","        # Add the token embeddings and position embeddings\n","        return x + positions"]},{"cell_type":"markdown","metadata":{},"source":["## Implement the Mini GPT\n","\n","### Hyperparameters"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T17:20:05.357876Z","iopub.status.busy":"2023-06-26T17:20:05.355340Z","iopub.status.idle":"2023-06-26T17:20:05.365581Z","shell.execute_reply":"2023-06-26T17:20:05.364699Z","shell.execute_reply.started":"2023-06-26T17:20:05.357844Z"},"trusted":true},"outputs":[],"source":["# vocab_size = 30000  # Only consider the top 20k words\n","maxlen = 80  # Max sequence size\n","embed_dim = 256  # Embedding size for each token\n","num_heads = 2  # Number of attention heads\n","feed_forward_dim = 256  # Hidden layer size in feed forward network inside transformer"]},{"cell_type":"markdown","metadata":{},"source":["### Function to Compile Model"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T17:20:05.370137Z","iopub.status.busy":"2023-06-26T17:20:05.369450Z","iopub.status.idle":"2023-06-26T17:20:05.381928Z","shell.execute_reply":"2023-06-26T17:20:05.381019Z","shell.execute_reply.started":"2023-06-26T17:20:05.370107Z"},"trusted":true},"outputs":[],"source":["def MiniGPT():\n","    \"\"\"\n","    Constructs a mini version of the GPT model. The architecture is comprised of a\n","    token and position embedding layer followed by a single Transformer block. The final\n","    layer is a dense layer with softmax activation for prediction. \n","\n","    Returns:\n","        keras.Model: Mini GPT model.\n","    \"\"\"\n","\n","    # Input layer expects inputs of shape (maxlen,) with type int32\n","    inputs = layers.Input(shape=(maxlen,), dtype=tf.int32)\n","\n","    # Create the token and position embedding layer and compute the embeddings\n","    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n","    x = embedding_layer(inputs)\n","\n","    # Create the Transformer block and compute its output\n","    transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n","    x = transformer_block(x)\n","\n","    # Final dense layer with size equal to the vocabulary size\n","    outputs = layers.Dense(vocab_size)(x)\n","\n","    # Construct the Keras model\n","    model = keras.Model(inputs=inputs, outputs=[outputs, x])\n","\n","    # Loss function for the training \n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","    # Model compilation: use Adam optimizer and the defined loss function\n","    # Note that we specify `None` for the second loss to not optimize based on the Transformer block's output\n","    model.compile(\"adam\", loss=[loss_fn, None])\n","    model.summary()\n","\n","    return model"]},{"attachments":{"a896bbaf-c33d-4700-b0b2-dc7aabd2e598.png":{"image/png":"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"}},"cell_type":"markdown","metadata":{},"source":["## Model Architecture\n","\n","***Shout out to this amazing app: https://netron.app/***\n","***You simply drag and drop your tensorflow or pytorch model into the app and it generates the diagram for you!***\n","\n","![Screen Shot 2023-06-25 at 6.55.38 PM.png](attachment:a896bbaf-c33d-4700-b0b2-dc7aabd2e598.png)"]},{"cell_type":"markdown","metadata":{},"source":["## Implement Text Generator Callback Object"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T17:20:05.388603Z","iopub.status.busy":"2023-06-26T17:20:05.386118Z","iopub.status.idle":"2023-06-26T17:20:05.409191Z","shell.execute_reply":"2023-06-26T17:20:05.408172Z","shell.execute_reply.started":"2023-06-26T17:20:05.388573Z"},"trusted":true},"outputs":[],"source":["class TextGenerator(keras.callbacks.Callback):\n","    \"\"\"\n","    A callback to generate text from a trained model at the end of each epoch. It uses the model's \n","    predictions to sample a token, add it to the input, and generate subsequent tokens.\n","\n","    Attributes:\n","        max_tokens (int): The number of tokens to be generated after the prompt.\n","        start_tokens (list): The token indices for the starting prompt.\n","        index_to_word (list): Mapping from token indices to words, obtained from the TextVectorization layer.\n","        k (int): Number of token predictions to consider for sampling the next token.\n","        print_every (int): Frequency of print for the generated text (in number of epochs).\n","    \"\"\"\n","    def __init__(self, max_tokens, start_tokens, index_to_word, top_k=20, print_every=1):\n","        \"\"\"\n","        Initializes the TextGenerator callback.\n","\n","        Args:\n","            max_tokens (int): Maximum number of tokens to be generated.\n","            start_tokens (list): List of integers representing the starting tokens.\n","            index_to_word (list): List of strings representing the mapping from indices to words.\n","            top_k (int, optional): Number of top token predictions to sample from. Defaults to 10.\n","            print_every (int, optional): Frequency of print (in number of epochs). Defaults to 1.\n","        \"\"\"\n","        super().__init__()\n","        self.max_tokens = max_tokens\n","        self.start_tokens = start_tokens\n","        self.index_to_word = index_to_word\n","        self.k = top_k\n","        self.print_every = print_every\n","        self.generated_texts = [] # for qualitative validation set\n","\n","    def sample_from(self, logits):\n","        \"\"\"\n","        Sample a token index from the token predictions based on their probabilities.\n","\n","        Args:\n","            logits (tf.Tensor): The token predictions (logits) of the model.\n","\n","        Returns:\n","            int: The sampled token index.\n","        \"\"\"\n","        # Select top-k logits and their indices\n","        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n","        indices = np.asarray(indices).astype(\"int32\")\n","\n","        # Apply softmax to transform logits into probabilities\n","        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n","        preds = np.asarray(preds).astype(\"float32\")\n","\n","        # Randomly select an index according to the probability distribution\n","        return np.random.choice(indices, p=preds)\n","\n","    def detokenize(self, number):\n","        \"\"\"\n","        Convert a token index into the corresponding word.\n","\n","        Args:\n","            number (int): The token index.\n","\n","        Returns:\n","            str: The corresponding word.\n","        \"\"\"\n","        return self.index_to_word[number]\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        \"\"\"\n","        At the end of each epoch, generate text and print it.\n","\n","        Args:\n","            epoch (int): The current epoch number.\n","            logs (dict, optional): Dictionary of metrics from the epoch. Defaults to None.\n","        \"\"\"\n","        # Create a copy of start tokens for generation\n","        start_tokens = [_ for _ in self.start_tokens]\n","\n","        # Only generate text at specified frequency\n","        if (epoch + 1) % self.print_every != 0:\n","            return\n","\n","        num_tokens_generated = 0\n","        tokens_generated = []\n","\n","        # Generate tokens until max tokens reached\n","        while num_tokens_generated <= self.max_tokens:\n","            pad_len = maxlen - len(start_tokens)\n","            sample_index = len(start_tokens) - 1\n","\n","            # Adjust padding based on length of start tokens\n","            if pad_len < 0:\n","                x = start_tokens[:maxlen]\n","                sample_index = maxlen - 1\n","            elif pad_len > 0:\n","                x = start_tokens + [0] * pad_len\n","            else:\n","                x = start_tokens\n","\n","            x = np.array([x])\n","\n","            # Use the model to predict the probabilities for the next token\n","            y, _ = self.model.predict(x)\n","\n","            # Sample a token from the model's output distribution\n","            sample_token = self.sample_from(y[0][sample_index])\n","\n","            # Append the token to the list of generated tokens\n","            tokens_generated.append(sample_token)\n","\n","            # Add the token to the start tokens for the next generation\n","            start_tokens.append(sample_token)\n","\n","            # Increase the number of tokens generated by 1\n","            num_tokens_generated = len(tokens_generated)\n","\n","        # Convert the tokens into actual words and join them into a string\n","        txt = \" \".join(\n","            [self.detokenize(_) for _ in self.start_tokens + tokens_generated]\n","        )\n","        \n","        self.generated_texts.append((epoch, txt)) # Store for evalutation after training\n","\n","\n","        # Print the generated text\n","        print(f\"generated text:\\n{txt}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["## Create Word/Index Mapping Dictionary "]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T17:20:05.416119Z","iopub.status.busy":"2023-06-26T17:20:05.413493Z","iopub.status.idle":"2023-06-26T17:20:05.444952Z","shell.execute_reply":"2023-06-26T17:20:05.444032Z","shell.execute_reply.started":"2023-06-26T17:20:05.416088Z"},"trusted":true},"outputs":[],"source":["## Tokenize starting prompt\n","word_to_index = {}\n","for index, word in enumerate(vocab):\n","    word_to_index[word] = index"]},{"cell_type":"markdown","metadata":{},"source":["## Initialize Callback Object\n","\n","***We also need to supply a starting prompt to act as a qualitative validation set to evaluate the models performance from a 'does it make more sense' per epoch. It will generate(predict) a text sequence continuation from the starting prompt at the end of every epoch to inspect.***"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T17:20:05.448052Z","iopub.status.busy":"2023-06-26T17:20:05.447220Z","iopub.status.idle":"2023-06-26T17:20:05.453238Z","shell.execute_reply":"2023-06-26T17:20:05.452137Z","shell.execute_reply.started":"2023-06-26T17:20:05.448021Z"},"trusted":true},"outputs":[],"source":["start_prompt = \"I would have\"\n","\n","start_tokens = [word_to_index.get(_, 1) for _ in start_prompt.split()]\n","num_tokens_generated = 42\n","text_gen_callback = TextGenerator(num_tokens_generated, start_tokens, vocab)"]},{"cell_type":"markdown","metadata":{},"source":["# Training\n","\n","***I apologize for the scrolling your about to do. I wanted to generate text at each epoch so that along with loss there would be some qualitative evaluation on the models performance throughout training but I could not find a way to remove the progress bars for each step inside the epochs... If anyone reading this knows a way please comment.***\n","\n","***Until about `25` epochs many of the generations depending on the satrting prompt during training had nonsensical outputs. So we will use `25` to get a good baseline model to evaluate.***"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-06-26T17:20:05.454927Z","iopub.status.busy":"2023-06-26T17:20:05.454411Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 80)]              0         \n","                                                                 \n"," token_and_position_embeddin  (None, 80, 256)          25620480  \n"," g_2 (TokenAndPositionEmbedd                                     \n"," ing)                                                            \n","                                                                 \n"," transformer_block_2 (Transf  (None, 80, 256)          658688    \n"," ormerBlock)                                                     \n","                                                                 \n"," dense_8 (Dense)             (None, 80, 100000)        25700000  \n","                                                                 \n","=================================================================\n","Total params: 51,979,168\n","Trainable params: 51,979,168\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"name":"stdout","output_type":"stream","text":["  79/5723 [..............................] - ETA: 19:59 - loss: 5.0344 - dense_8_loss: 5.0344"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-13fb3b877c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_gen_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = MiniGPT()\n","\n","N_EPOCHS = 1\n","history  = model.fit(text_ds, verbose=1, epochs=N_EPOCHS, callbacks=[text_gen_callback])"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate Training Loss Per Epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot training loss\n","plt.figure(figsize=(12, 6))\n","plt.plot(history.history['loss'])\n","plt.title('Training loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train'], loc='upper right')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate Validation Set Per Epoch\n","\n","***Since we don't have a quantitative validation set in this situation we can use a qualitative validation set. These would be the generated text from the end of each epoch. This can give us some clues along with the losses per epoch to see how the models performance progressed through training.***\n","\n","***Lets inspect what the first five generations look llike compared to the last five during training.***"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# for epoch, text in text_gen_callback.generated_texts:\n","#     print(f\"Epoch: {epoch+1}\\nGenerated Text:\\n{text}\\n\")\n","    # Create a DataFrame\n","    \n","df_val = pd.DataFrame(text_gen_callback.generated_texts, columns=['Epoch', 'Generated Text'])\n","\n","display(df_val.head(5));df_val.tail(5)"]},{"cell_type":"markdown","metadata":{},"source":["***It appears to that with more iterations the model becomes more and more realistic in its generations. The model starts producing less unknown tokens over time during training iterations.***"]},{"cell_type":"markdown","metadata":{},"source":["## Inference\n","\n","***Now that we have trained the model to generate toxic comments from a starting prompt we can begin to generate our synthetic data.***"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def generate_text(starting_prompt=''):\n","    new_start_prompt = \"here we\"\n","    new_start_tokens = [word_to_index.get(word, 1) for word in new_start_prompt.split()]\n","\n","    text_gen_callback.start_tokens = new_start_tokens\n","    text_gen_callback.on_epoch_end(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generate_text(\"you sure\")"]},{"cell_type":"markdown","metadata":{},"source":["# Conclusion\n","\n","## State of training data\n","\n","* I learned alot on this project. It is interesting to me that with all of the data in the world there is still a shortage of industrial sized, cleaned, organized, and labeled training data. \n","\n","* It would seem that allthough in academia the glory goes to the next new model or algorithm when really the training data is probably more important at this point. It does not matter how fancy an algorithm is(some of them are pretty fancy) or a model is, without good training data we are limited in the problems we can tackle effectively.\n","\n","* During this project I researched training data sets and where they come from. Most of the open source ones come from a handful of instituions namely universities with a few corporations willing to share the training datasets or models which would not effect their market share significantly releasing them.\n","\n","* Even the sensitive subjetcs such as the language used in this projects training data is very important to solve very prominent problems we have.\n","\n","## Decisions made along the way\n","* I started off this project trying to adapt a GAN to acheive this tast but there is little work done in this area and I had a lot of trouble trying to implement one of the papers where they achieve this task.\n","\n","* I chose this method as this model is lightweight and quick to train and tune for any specific style of language. As I mentioned at the beginning I originally tested this capabillity on the movie lines IMDB dataset and had great results. \n","\n","* The dataset I used turned out to be admittedly smaller than probably needed to get better results but I am confident that once I wrange up more nasty online comments the model will do much better after retraining.\n","\n","* The feature dimensions in the attention head made a huge difference on training time and performance. I had better results at 512 than it is currently at (256) but the time to train 25 epochs grew exponentially. If I had more Kaggle GPU hours I would have done my final training round with 512 in the attention head.\n","\n","* I originally tried a custom learning rate optimizing function but because of the large differences in epochs I was trying for different experiments I switched over to just using ADAM for this task.\n","\n","* The starting prompt matters. I found out that after looking at the popular bigrams and trigrams if I chose those sequences the model would generate sensible text more easily. \n","\n","* The length of the starting prompt also effects how different each output is dramatically.\n","\n","## Whats Next\n","\n","* I am going to run this model and compile a set of generated texts which are known to be toxic and add them to the training set and retrain the BERT based model I used when competing in this competition to see what results I get with the added training data.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Save and load model for future use"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_path = '../working/Toxic_MiniGPT.h5'\n","\n","# Save the model\n","model.save(model_path)\n","\n","## Load the model\n","from tensorflow.keras.models import load_model\n","\n","# Register the custom layer\n","tf.keras.utils.get_custom_objects()['TransformerBlock'] = TransformerBlock\n","\n","# Load the model\n","model = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
