{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniGPT For Generating Synthetic Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Toxic comments online come in many forms and in many arenas. There are currently several ways to mitigate these comments(for those organizations who wish to do so). Some of these ways include human moderators, and training machine learning models to detect toxicity in online comments.\n",
    "\n",
    "The issue with human moderators is that some of these platforms have grown so large so quickly that there are not nearly enough moderators to achieve any sense of control for most of these comments. The shear volume of toxicity and bots online makes it unrealistic to think we could do this job with humans at this point.\n",
    "\n",
    "Many companies are employing machine learning to assist with identifying toxic comments online automatically. The problem with this approach is the lack of labeled training data to train the models on.\n",
    "\n",
    "This is the problem I am going to solve using generative deep learning techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/ubuntu/.local/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/.local/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.8/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "## set seeds for repeatable conclusion\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The data I will be using to train the generative model was released on Kaggle as part of an ongoing series of competitions sponsored by the [Google company Jigsaw](https://en.wikipedia.org/wiki/Jigsaw_(company)).\n",
    "\n",
    "The data consists of online comments with various severity levels of toxicity. There are versions of these comments labeled by human annotators wherein they label each comment as toxic or not, or other sets where they were labeled as different categories of toxic such as hatespeech, racist/sexist, obscene, etc. Although these are the labeled datasets we would be adding the synthetic data to in order to create more training data, for this task of simply generating similar text data we will only focus on the comments themselves.\n",
    "\n",
    "The data provided by this competition includes a total of `14,251` unique toxic comments. Theses are the comments I will use to train the generative model with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "The data came in two different files.\n",
    "\n",
    "1) Comments to score: This acts as a test dataset of comments for scoring after the model was trained.\n",
    "\n",
    "2) Validation data: This was the training data for the competition wherein there are two columns. One column labeled less toxic was a comment which human annotators labeled as less toxic than its more toxic counterpart in the other column. There was no actual training data where a comment was paired with its severity rating. The models were trained using creative techniques with the validation data and other classification data sets to train a model which predicted severity of comments.\n",
    "\n",
    "Since for our purposes we are only interested in the actual text comments themselves, I will only be using those columns from these datasources.\n",
    "\n",
    "I start by reading them all into pandas dataframes, isolating the text columns from each one, and stacking them all together so we have a single column of text when it is all said and done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7537 entries, 0 to 7536\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   comment_id  7537 non-null   int64 \n",
      " 1   text        7537 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "601                               silly little boy my ass\n",
       "2031    Is that so? Than why so many people questiong ...\n",
       "1928     Wow \\nThanks! You are SO amazing! I am in awe...\n",
       "468     \"\\n\\n Send this to User:Bumpusmills1 \\n\\nPass ...\n",
       "6351    \"\\n\\nthat is your opinion. And what is your pr...\n",
       "748      man its all about captain morgans spiced rum....\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('comments_to_score.csv')\n",
    "data1.info()\n",
    "\n",
    "## Isolate only text column\n",
    "data1 = data1['text']\n",
    "\n",
    "data1.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We can see the comments to score was the test file which contained only comments and their corresponding id's***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30108 entries, 0 to 30107\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   worker      30108 non-null  int64 \n",
      " 1   less_toxic  30108 non-null  object\n",
      " 2   more_toxic  30108 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 705.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19699</th>\n",
       "      <td>193</td>\n",
       "      <td>I agree \\n\\nDayewalker is just another republ...</td>\n",
       "      <td>question \\n\\ncan I please ask you a question?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15268</th>\n",
       "      <td>240</td>\n",
       "      <td>Are there Turks live? LOL I have never get  re...</td>\n",
       "      <td>WHY DONT YOU FUCK OFF YOU MANWHORE AND LET US ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16859</th>\n",
       "      <td>652</td>\n",
       "      <td>Burn In Hell Paulley \\nEvery time I try to ed...</td>\n",
       "      <td>you fucking piece of shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>513</td>\n",
       "      <td>LAWL \\n\\nlulz @ u nerd, keep deleting my comm...</td>\n",
       "      <td>John Cena's wrestling abilities\\nJohn Cena is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14019</th>\n",
       "      <td>527</td>\n",
       "      <td>Your vandalism \\nPlease stop. If you continue...</td>\n",
       "      <td>As for [http://en.wikipedia.org/w/index.php?ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26733</th>\n",
       "      <td>201</td>\n",
       "      <td>LOL what a load of unsourced, unscientific bu...</td>\n",
       "      <td>Todo speedy deletion candidates \\n\\nI do not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "19699     193   I agree \\n\\nDayewalker is just another republ...   \n",
       "15268     240  Are there Turks live? LOL I have never get  re...   \n",
       "16859     652   Burn In Hell Paulley \\nEvery time I try to ed...   \n",
       "12496     513   LAWL \\n\\nlulz @ u nerd, keep deleting my comm...   \n",
       "14019     527   Your vandalism \\nPlease stop. If you continue...   \n",
       "26733     201   LOL what a load of unsourced, unscientific bu...   \n",
       "\n",
       "                                              more_toxic  \n",
       "19699   question \\n\\ncan I please ask you a question?...  \n",
       "15268  WHY DONT YOU FUCK OFF YOU MANWHORE AND LET US ...  \n",
       "16859                         you fucking piece of shit   \n",
       "12496  John Cena's wrestling abilities\\nJohn Cena is ...  \n",
       "14019  As for [http://en.wikipedia.org/w/index.php?ti...  \n",
       "26733   Todo speedy deletion candidates \\n\\nI do not ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('validation_data.csv')\n",
    "data2.info()\n",
    "\n",
    "data2.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2447 entries, 0 to 2446\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             2447 non-null   object\n",
      " 1   comment_text   2447 non-null   object\n",
      " 2   toxic          2447 non-null   int64 \n",
      " 3   severe_toxic   2447 non-null   int64 \n",
      " 4   obscene        2447 non-null   int64 \n",
      " 5   threat         2447 non-null   int64 \n",
      " 6   insult         2447 non-null   int64 \n",
      " 7   identity_hate  2447 non-null   int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 153.1+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-64cbe9b74f8b>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data4 = pd.read_csv('jigsaw-toxic-comment-train.csv',error_bad_lines=False, engine=\"python\")\n",
      "Skipping line 2449: unexpected end of data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>006e87872c8b370c</td>\n",
       "      <td>you are a stupid fuck \\n\\nand your mother's cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>022af9360c61f05f</td>\n",
       "      <td>Groin \\n\\nYou sad fuck. I'm going to restore m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>047b26be7714316a</td>\n",
       "      <td>\"\\n\\nYou have evidence from ME!  I presented y...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>026a530134212936</td>\n",
       "      <td>\"\\n\\n I TAKE OFFENSE! \\n\\nI take great offense...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>02c5be40edbd40cc</td>\n",
       "      <td>WikiDon, STOP stalking me!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>04316638593290c8</td>\n",
       "      <td>I'm the one that went to get help from the adm...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                       comment_text  \\\n",
       "181   006e87872c8b370c  you are a stupid fuck \\n\\nand your mother's cu...   \n",
       "815   022af9360c61f05f  Groin \\n\\nYou sad fuck. I'm going to restore m...   \n",
       "1654  047b26be7714316a  \"\\n\\nYou have evidence from ME!  I presented y...   \n",
       "884   026a530134212936  \"\\n\\n I TAKE OFFENSE! \\n\\nI take great offense...   \n",
       "1015  02c5be40edbd40cc                         WikiDon, STOP stalking me!   \n",
       "1559  04316638593290c8  I'm the one that went to get help from the adm...   \n",
       "\n",
       "      toxic  severe_toxic  obscene  threat  insult  identity_hate  sum  \n",
       "181       1             1        1       0       1              0    4  \n",
       "815       1             0        1       0       1              0    3  \n",
       "1654      1             0        1       0       1              1    4  \n",
       "884       1             0        0       0       0              0    1  \n",
       "1015      1             0        0       0       0              0    1  \n",
       "1559      1             0        0       0       0              0    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4 = pd.read_csv('jigsaw-toxic-comment-train.csv',error_bad_lines=False, engine=\"python\")\n",
    "data4 = data4.dropna(how='all')\n",
    "data4.info()\n",
    "\n",
    "## Sum across labels to filter out clean comments\n",
    "data4['sum'] = data4.loc[:, 'toxic':].sum(axis=1)\n",
    "\n",
    "## Keep only comments with some type of label\n",
    "data4 = data4[data4['sum'] > 0]\n",
    "\n",
    "data4.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-f9d521d710fd>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data5 = pd.read_csv('jigsaw-unintended-bias-train.csv',error_bad_lines=False, engine=\"python\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21911 entries, 0 to 21910\n",
      "Data columns (total 45 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   id                                   21911 non-null  int64  \n",
      " 1   comment_text                         21911 non-null  object \n",
      " 2   toxic                                21911 non-null  float64\n",
      " 3   severe_toxicity                      21911 non-null  float64\n",
      " 4   obscene                              21911 non-null  float64\n",
      " 5   identity_attack                      21911 non-null  float64\n",
      " 6   insult                               21911 non-null  float64\n",
      " 7   threat                               21911 non-null  float64\n",
      " 8   asian                                4536 non-null   float64\n",
      " 9   atheist                              4536 non-null   float64\n",
      " 10  bisexual                             4536 non-null   float64\n",
      " 11  black                                4536 non-null   float64\n",
      " 12  buddhist                             4536 non-null   float64\n",
      " 13  christian                            4536 non-null   float64\n",
      " 14  female                               4536 non-null   float64\n",
      " 15  heterosexual                         4536 non-null   float64\n",
      " 16  hindu                                4536 non-null   float64\n",
      " 17  homosexual_gay_or_lesbian            4536 non-null   float64\n",
      " 18  intellectual_or_learning_disability  4536 non-null   float64\n",
      " 19  jewish                               4536 non-null   float64\n",
      " 20  latino                               4536 non-null   float64\n",
      " 21  male                                 4536 non-null   float64\n",
      " 22  muslim                               4536 non-null   float64\n",
      " 23  other_disability                     4536 non-null   float64\n",
      " 24  other_gender                         4536 non-null   float64\n",
      " 25  other_race_or_ethnicity              4536 non-null   float64\n",
      " 26  other_religion                       4536 non-null   float64\n",
      " 27  other_sexual_orientation             4536 non-null   float64\n",
      " 28  physical_disability                  4536 non-null   float64\n",
      " 29  psychiatric_or_mental_illness        4536 non-null   float64\n",
      " 30  transgender                          4536 non-null   float64\n",
      " 31  white                                4536 non-null   float64\n",
      " 32  created_date                         21910 non-null  object \n",
      " 33  publication_id                       21910 non-null  float64\n",
      " 34  parent_id                            11510 non-null  float64\n",
      " 35  article_id                           21910 non-null  float64\n",
      " 36  rating                               21910 non-null  object \n",
      " 37  funny                                21910 non-null  float64\n",
      " 38  wow                                  21910 non-null  float64\n",
      " 39  sad                                  21910 non-null  float64\n",
      " 40  likes                                21910 non-null  float64\n",
      " 41  disagree                             21910 non-null  float64\n",
      " 42  sexual_explicit                      21910 non-null  float64\n",
      " 43  identity_annotator_count             21910 non-null  float64\n",
      " 44  toxicity_annotator_count             21910 non-null  float64\n",
      "dtypes: float64(41), int64(1), object(3)\n",
      "memory usage: 7.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21804</th>\n",
       "      <td>268802</td>\n",
       "      <td>Bird watching can bring in big bucks. So can n...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17889</th>\n",
       "      <td>264112</td>\n",
       "      <td>seems to me Dick your padding your assumptions...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17676</th>\n",
       "      <td>263870</td>\n",
       "      <td>Actually kids aren't stupid these days they kn...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>259216</td>\n",
       "      <td>Don't forget the fish processing plant which i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>242636</td>\n",
       "      <td>Yes, I was intending to compare both factors. ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>245998</td>\n",
       "      <td>must we go through this again.......  BTW:  he...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                       comment_text  toxic  \\\n",
       "21804  268802  Bird watching can bring in big bucks. So can n...    0.2   \n",
       "17889  264112  seems to me Dick your padding your assumptions...    0.2   \n",
       "17676  263870  Actually kids aren't stupid these days they kn...    0.4   \n",
       "13810  259216  Don't forget the fish processing plant which i...    0.0   \n",
       "1683   242636  Yes, I was intending to compare both factors. ...    0.0   \n",
       "3930   245998  must we go through this again.......  BTW:  he...    0.2   \n",
       "\n",
       "       severe_toxicity  obscene  identity_attack  insult  threat  asian  \\\n",
       "21804              0.0      0.0              0.0     0.0     0.2    NaN   \n",
       "17889              0.0      0.1              0.0     0.2     0.0    NaN   \n",
       "17676              0.0      0.2              0.1     0.4     0.0    NaN   \n",
       "13810              0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "1683               0.0      0.0              0.0     0.0     0.0    0.0   \n",
       "3930               0.0      0.0              0.0     0.0     0.0    NaN   \n",
       "\n",
       "       atheist  ...  other_gender  other_race_or_ethnicity  other_religion  \\\n",
       "21804      NaN  ...           NaN                      NaN             NaN   \n",
       "17889      NaN  ...           NaN                      NaN             NaN   \n",
       "17676      NaN  ...           NaN                      NaN             NaN   \n",
       "13810      0.0  ...           0.0                      0.0             0.0   \n",
       "1683       0.0  ...           0.0                      0.0             0.0   \n",
       "3930       NaN  ...           NaN                      NaN             NaN   \n",
       "\n",
       "       other_sexual_orientation  physical_disability  \\\n",
       "21804                       NaN                  NaN   \n",
       "17889                       NaN                  NaN   \n",
       "17676                       NaN                  NaN   \n",
       "13810                       0.0                  0.0   \n",
       "1683                        0.0                  0.0   \n",
       "3930                        NaN                  NaN   \n",
       "\n",
       "       psychiatric_or_mental_illness  transgender  white  sexual_explicit  \\\n",
       "21804                            NaN          NaN    NaN              0.0   \n",
       "17889                            NaN          NaN    NaN              0.0   \n",
       "17676                            NaN          NaN    NaN              0.0   \n",
       "13810                            0.0          0.0    0.0              0.0   \n",
       "1683                             0.0          0.0    0.0              0.0   \n",
       "3930                             NaN          NaN    NaN              0.0   \n",
       "\n",
       "            sum  \n",
       "21804  0.400000  \n",
       "17889  0.500000  \n",
       "17676  1.100000  \n",
       "13810  0.166667  \n",
       "1683   0.700000  \n",
       "3930   0.200000  \n",
       "\n",
       "[6 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5 = pd.read_csv('jigsaw-unintended-bias-train.csv',error_bad_lines=False, engine=\"python\")\n",
    "data5.info()\n",
    "\n",
    "drop_columns = [\n",
    "    'created_date',\n",
    "    'publication_id',\n",
    "    'parent_id',\n",
    "    'article_id', \n",
    "    'rating', \n",
    "    'funny', \n",
    "    'wow', \n",
    "    'sad', \n",
    "    'likes', \n",
    "    'disagree', \n",
    "    'identity_annotator_count', \n",
    "    'toxicity_annotator_count'\n",
    "]\n",
    "\n",
    "data5 = data5.drop(columns=drop_columns, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Sum across labels to filter out clean comments\n",
    "data5['sum'] = data5.loc[:, 'toxic':].sum(axis=1)\n",
    "\n",
    "## Keep only comments with some type of label\n",
    "data5 = data5[data5['sum'] > 0]\n",
    "\n",
    "data5.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This was the data provided to validate the models performance during training. The three columns are workers(annotators) and the other two are text columns which we will use both to train our generative model with.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all columns into a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Isolate text column\n",
    "data2 = data2['more_toxic']\n",
    "data4 = data4['comment_text']\n",
    "data5 = data5['comment_text']\n",
    "\n",
    "## Isolate text column\n",
    "data3 = pd.read_csv('validation_data.csv')\n",
    "data3 = data3['less_toxic']\n",
    "\n",
    "text_column = pd.concat([data1, data2, data3, data4, data5], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " sorry i jumped to conclusions \\n\\non christian terrorism article man, I don't agree with you, and I want you to go and listen to 'prophet of doom' (now in audio format) as it is good. But I was wrong to be so rude. It is not the Southern European way.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           19\n",
       "this irishtom guy is turning every article into an ad for islam                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        19\n",
       "You are not sorry one damned bit.  You have yet to refute what I have written.  All you do is pass the insults as if it were salt on the dinner table.  This is on every article in which we disagree.  If you have something useful and constructive to say, then don't be a harpy troll.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             19\n",
       "ScJessey is a Big Fat Faggot Pinko Commie Asshole                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      16\n",
       "\"\\n\\nHas he called himself a Nazi, or is that just what an opponent called him? Look, Untwirl, I have been a Socialist my entire life, but I will not put down someone I don't like as \"\"right-wing.\"\" life to more complex than that. Sometimes I like those right wingers better than my political \"\"friends\"\", who often act like jerks.   \"                                                                                                                                                                                                                                                                                                                                                                                                                                                        16\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ..\n",
       "This ruling will be overturned. It is unconstitutional on its face and if upheld would subject any writer, including journalists, to damages for writing something true if the plaintiff's feelings were hurt.  \\n\\nFor example, let's say a blogger wrote a series of stories about a corrupt law firm that over-bills its clients and tears families apart for the sole purpose of making money. While I appreciate that some very bad people don't like the light of truth being shone upon them, they should take no comfort in this case.  It will not stand, and I for one do not feel at all threatened by it, even as they post this story on Facebook as a warning.\\n\\nThe judge should have issued a judgment notwithstanding the verdict immediately. I hope this man appeals this case.     1\n",
       "Sounds like a guy who couldn't get laid with his own hand.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
       "He didn't say that, you are twisting his words and is not cool.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
       "Oregon: Of course it's a defunct justice system. For one, you  vote Liberal, invest millions in social services and have little hippy communities that only serve as cesspools for creeps like this. Funny I hear time and time again about Red States supposed anti-woman policies while something this \"anti-woman\" is happening in one of the most Liberal states in the country. For two, when something like this actually happens you cry foul and struggle to take action but the real problem is the hypocrisy in it all.  The truth is when all that fake idealism is replaced with a healthy realism, you will vote republican and guys like this will be off the street. Stop contributing to the problem and be a part of the solution.                                                     1\n",
       "Jesus associated with the outcasts of society ... more clear?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\n",
       "Length: 21413, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_column.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like between the data provided for the competition there are many duplicates. However we can see that some comments are reused many more times than other comments. For example the most used comments were repeated `19` times in the datasets while others only `2` times. \n",
    "\n",
    "Since the duplications are not balanced if we left the data like this I am afraid we would be biasing the model towards the comments which were present more in the data. \n",
    "\n",
    "I will remove all duplicate comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numer of comments in text data = 74997\n",
      "Numer of unique comments in text data = 21413\n",
      "Duplicate comments dropped\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total numer of comments in text data = {len(text_column)}\")\n",
    "print(f\"Numer of unique comments in text data = {len(text_column.unique())}\")\n",
    "\n",
    "text_column = text_column.drop_duplicates()\n",
    "print(\"Duplicate comments dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>noun_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>109.430000</td>\n",
       "      <td>12.220000</td>\n",
       "      <td>18.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>350.612804</td>\n",
       "      <td>14.977141</td>\n",
       "      <td>22.298218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>103.750000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>23.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3469.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_count  verb_count  noun_count\n",
       "count   100.000000  100.000000  100.000000\n",
       "mean    109.430000   12.220000   18.960000\n",
       "std     350.612804   14.977141   22.298218\n",
       "min       3.000000    0.000000    0.000000\n",
       "25%      20.750000    3.000000    6.000000\n",
       "50%      46.000000    8.000000   12.000000\n",
       "75%     103.750000   18.250000   23.250000\n",
       "max    3469.000000   89.000000  121.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['text'] = text_column\n",
    "data = data.sample(100)\n",
    "\n",
    "# Function to calculate word count\n",
    "def count_words(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return len(words)\n",
    "\n",
    "# Function to calculate verb count\n",
    "def count_verbs(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    verb_count = len([word for word, tag in tagged_words if tag.startswith('V')])\n",
    "    return verb_count\n",
    "\n",
    "# Function to calculate noun count\n",
    "def count_nouns(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    noun_count = len([word for word, tag in tagged_words if tag.startswith('N')])\n",
    "    return noun_count\n",
    "\n",
    "# Add word count column\n",
    "data['word_count'] = data['text'].apply(count_words)\n",
    "\n",
    "# Add verb count column\n",
    "data['verb_count'] = data['text'].apply(count_verbs)\n",
    "\n",
    "# Add noun count column\n",
    "data['noun_count'] = data['text'].apply(count_nouns)\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = data['word_count'].plot(kind='kde')\n",
    "data['verb_count'].plot(kind='kde', ax=ax)\n",
    "data['noun_count'].plot(kind='kde', ax=ax)\n",
    "\n",
    "ax.legend(['Word Count', 'Verb Count', 'Noun Count'])\n",
    "ax.set_title('Distribution of Word Count, Verb Count, and Noun Count')\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these comments on average are quite short in length and contain more nouns than verbs on average.\n",
    "\n",
    "Since we have not done any cleaning of the data yet these distributions are not exact as the nltk package is not currently looking for misspelled words or different versions of word spellings which are used online sometimes.\n",
    "\n",
    "For example if a user knows that the platform they are on has limitations on language than they may spell a profane word to try to fool any auto detecting systems such as `Fuck==>Fxck, F*ck, Fukk, Fuuu*uukk`, etc.\n",
    "\n",
    "Therefore these counts will not detect all nouns and verbs but should give a decent sample.\n",
    "\n",
    "Knowing the underlying distributions of some of these features is important because after the synthetic data is generated we would most likely want it to follow the same distributions for these attributes of the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the most common N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((!, !), 3245)</td>\n",
       "      <td>((!, !, !), 3184)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((LUNCHABLES, !), 53)</td>\n",
       "      <td>((LUNCHABLES, !, !), 53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((!, 1lol), 52)</td>\n",
       "      <td>((!, !, 1lol), 52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((1lol, imma), 52)</td>\n",
       "      <td>((!, 1lol, imma), 52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((imma, donkey), 52)</td>\n",
       "      <td>((1lol, imma, donkey), 52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((donkey, LUNCHABLES), 52)</td>\n",
       "      <td>((imma, donkey, LUNCHABLES), 52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(('', ''), 41)</td>\n",
       "      <td>((donkey, LUNCHABLES, !), 52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((., I), 40)</td>\n",
       "      <td>((., '', ''), 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((``, ''), 37)</td>\n",
       "      <td>((talk, page, .), 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((of, the), 24)</td>\n",
       "      <td>((., I, am), 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>((on, the), 23)</td>\n",
       "      <td>((I, do, n't), 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>((,, and), 23)</td>\n",
       "      <td>((., If, you), 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>((do, n't), 17)</td>\n",
       "      <td>((I, am, not), 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>((talk, page), 15)</td>\n",
       "      <td>((., I, do), 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>((I, am), 14)</td>\n",
       "      <td>((on, the, talk), 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>((in, the), 13)</td>\n",
       "      <td>((the, talk, page), 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>((., You), 13)</td>\n",
       "      <td>((you, ca, n't), 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>((to, the), 12)</td>\n",
       "      <td>((a, ``, ''), 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>((,, you), 12)</td>\n",
       "      <td>((., You, are), 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>((., The), 12)</td>\n",
       "      <td>((:, ``, ''), 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>((., ''), 12)</td>\n",
       "      <td>((., I, have), 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>((if, you), 11)</td>\n",
       "      <td>(([, .., ]), 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>((,, I), 11)</td>\n",
       "      <td>((You, are, an), 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>((it, 's), 11)</td>\n",
       "      <td>((I, suggest, you), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>((You, are), 10)</td>\n",
       "      <td>((is, not, the), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>((I, do), 10)</td>\n",
       "      <td>((,, in, my), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>((is, a), 10)</td>\n",
       "      <td>((,, I, do), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>((page, .), 9)</td>\n",
       "      <td>((,, ,, and), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>((,, but), 9)</td>\n",
       "      <td>((that, ``, ''), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>((is, not), 9)</td>\n",
       "      <td>((., SA, wrote), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>((you, are), 9)</td>\n",
       "      <td>((SA, wrote, :), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>((,, it), 9)</td>\n",
       "      <td>((wrote, :, ``), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>((at, the), 9)</td>\n",
       "      <td>((any, of, the), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>((I, 'm), 9)</td>\n",
       "      <td>((of, the, articles), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>((the, same), 8)</td>\n",
       "      <td>((., This, is), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>((you, have), 8)</td>\n",
       "      <td>((do, n't, want), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>((,, the), 8)</td>\n",
       "      <td>((n't, want, to), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>((have, to), 8)</td>\n",
       "      <td>((., I, will), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>((for, the), 8)</td>\n",
       "      <td>((,, etc, .), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>((the, article), 8)</td>\n",
       "      <td>((as, well, as), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>((has, been), 8)</td>\n",
       "      <td>((the, ``, ''), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>((to, make), 7)</td>\n",
       "      <td>(('s, talk, page), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>((., It), 7)</td>\n",
       "      <td>((to, do, with), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>((it, is), 7)</td>\n",
       "      <td>((why, did, you), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>((want, to), 7)</td>\n",
       "      <td>((my, talk, page), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>((I, have), 7)</td>\n",
       "      <td>((!, You, are), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>((like, you), 7)</td>\n",
       "      <td>((are, an, old), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>((you, can), 7)</td>\n",
       "      <td>((an, old, cougar), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>((have, been), 7)</td>\n",
       "      <td>((old, cougar, !), 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>((ca, n't), 6)</td>\n",
       "      <td>((., I, 'm), 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       bigrams                          trigrams\n",
       "0               ((!, !), 3245)                 ((!, !, !), 3184)\n",
       "1        ((LUNCHABLES, !), 53)          ((LUNCHABLES, !, !), 53)\n",
       "2              ((!, 1lol), 52)                ((!, !, 1lol), 52)\n",
       "3           ((1lol, imma), 52)             ((!, 1lol, imma), 52)\n",
       "4         ((imma, donkey), 52)        ((1lol, imma, donkey), 52)\n",
       "5   ((donkey, LUNCHABLES), 52)  ((imma, donkey, LUNCHABLES), 52)\n",
       "6               (('', ''), 41)     ((donkey, LUNCHABLES, !), 52)\n",
       "7                 ((., I), 40)                 ((., '', ''), 11)\n",
       "8               ((``, ''), 37)              ((talk, page, .), 6)\n",
       "9              ((of, the), 24)                   ((., I, am), 6)\n",
       "10             ((on, the), 23)                 ((I, do, n't), 6)\n",
       "11              ((,, and), 23)                 ((., If, you), 5)\n",
       "12             ((do, n't), 17)                 ((I, am, not), 5)\n",
       "13          ((talk, page), 15)                   ((., I, do), 5)\n",
       "14               ((I, am), 14)              ((on, the, talk), 4)\n",
       "15             ((in, the), 13)            ((the, talk, page), 4)\n",
       "16              ((., You), 13)               ((you, ca, n't), 4)\n",
       "17             ((to, the), 12)                  ((a, ``, ''), 4)\n",
       "18              ((,, you), 12)                ((., You, are), 4)\n",
       "19              ((., The), 12)                  ((:, ``, ''), 4)\n",
       "20               ((., ''), 12)                 ((., I, have), 4)\n",
       "21             ((if, you), 11)                   (([, .., ]), 4)\n",
       "22                ((,, I), 11)               ((You, are, an), 4)\n",
       "23              ((it, 's), 11)            ((I, suggest, you), 3)\n",
       "24            ((You, are), 10)               ((is, not, the), 3)\n",
       "25               ((I, do), 10)                  ((,, in, my), 3)\n",
       "26               ((is, a), 10)                   ((,, I, do), 3)\n",
       "27              ((page, .), 9)                  ((,, ,, and), 3)\n",
       "28               ((,, but), 9)               ((that, ``, ''), 3)\n",
       "29              ((is, not), 9)               ((., SA, wrote), 3)\n",
       "30             ((you, are), 9)               ((SA, wrote, :), 3)\n",
       "31                ((,, it), 9)               ((wrote, :, ``), 3)\n",
       "32              ((at, the), 9)               ((any, of, the), 3)\n",
       "33                ((I, 'm), 9)          ((of, the, articles), 3)\n",
       "34            ((the, same), 8)                ((., This, is), 3)\n",
       "35            ((you, have), 8)              ((do, n't, want), 3)\n",
       "36               ((,, the), 8)              ((n't, want, to), 3)\n",
       "37             ((have, to), 8)                 ((., I, will), 3)\n",
       "38             ((for, the), 8)                  ((,, etc, .), 3)\n",
       "39         ((the, article), 8)               ((as, well, as), 3)\n",
       "40            ((has, been), 8)                ((the, ``, ''), 3)\n",
       "41             ((to, make), 7)             (('s, talk, page), 3)\n",
       "42                ((., It), 7)               ((to, do, with), 3)\n",
       "43               ((it, is), 7)              ((why, did, you), 3)\n",
       "44             ((want, to), 7)             ((my, talk, page), 3)\n",
       "45              ((I, have), 7)                ((!, You, are), 3)\n",
       "46            ((like, you), 7)               ((are, an, old), 3)\n",
       "47             ((you, can), 7)            ((an, old, cougar), 3)\n",
       "48           ((have, been), 7)             ((old, cougar, !), 3)\n",
       "49              ((ca, n't), 6)                   ((., I, 'm), 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text into words\n",
    "data['words'] = data['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "# Get bigrams and trigrams for each row\n",
    "data['bigrams']   = data['words'].apply(lambda x: list(ngrams(x, 2)))\n",
    "data['trigrams']  = data['words'].apply(lambda x: list(ngrams(x, 3)))\n",
    "# data['quadgrams'] = data['words'].apply(lambda x: list(ngrams(x, 4)))\n",
    "\n",
    "# Count the occurrences of bigrams and trigrams\n",
    "bigram_counts   = Counter([gram for grams in data['bigrams'] for gram in grams])\n",
    "trigram_counts  = Counter([gram for grams in data['trigrams'] for gram in grams])\n",
    "# quadgram_counts = Counter([gram for grams in data['quadgrams'] for gram in grams])\n",
    "\n",
    "# Get the most common bigrams, trigrams, and quadgrams\n",
    "most_common_bigrams   = bigram_counts.most_common(50)\n",
    "most_common_trigrams  = trigram_counts.most_common(50)\n",
    "# most_common_quadgrams = quadgram_counts.most_common(50)\n",
    "\n",
    "df_common_grams = pd.DataFrame()\n",
    "df_common_grams['bigrams']   = most_common_bigrams\n",
    "df_common_grams['trigrams']  = most_common_trigrams\n",
    "# df_common_grams['quadgrams'] = most_common_quadgrams\n",
    "\n",
    "# # Display the results\n",
    "# print('Most common bigrams:')\n",
    "# for bigram, count in most_common_bigrams:\n",
    "#     print(' '.join(bigram), count)\n",
    "\n",
    "# print('\\nMost common trigrams:')\n",
    "# for trigram, count in most_common_trigrams:\n",
    "#     print(' '.join(trigram), count)\n",
    "    \n",
    "# print('\\nMost common quadgrams:')\n",
    "# for quadgram, count in most_common_quadgrams:\n",
    "#     print(' '.join(quadgram), count)\n",
    "\n",
    "\n",
    "df_common_grams.iloc[:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the initial 10 or so most common bi-grams and tri-grams are repetitive punctuation marks.\n",
    "\n",
    "Traditionally these would be cleaned and removed when training models for NLP tasks, however due to the nature of this work many of these traditional techniques will limit the models ability to predict toxicity as well as with clean text.\n",
    "\n",
    "I happened to have competed in this competition and one thing all of us learned was that leaving capital letters and punctuation improved the models ability to infer toxicity and especially levels of toxicity. \n",
    "\n",
    "For example a phrase such as:\n",
    "\n",
    "`Are you kidding?`\n",
    "\n",
    "Conveys a much different meaning than the same words but put this way:\n",
    "\n",
    "`ARE YOU KIDDING!!!??`\n",
    "\n",
    "Traditional NLP techniques would have us convert all characters to lower case and remove punctuation so the model will interpret both of those texts the exact same way.\n",
    "\n",
    "When training sentiment based models or models where feeling and emotion is being conveyed in some way such as toxicity of comments, it is more than just the raw content of the words alone which gives the meaning. The puncuation and capitalizations are very expressive forms of language and as such for these problems do better left in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "* First we need load in our text column as tensorflow formatted dataset\n",
    "\n",
    "* Next we shuffle the data to avoid any patterns which may have been present\n",
    "\n",
    "* We then slice the data into batches for processing\n",
    "\n",
    "* Vectorize the text which will be used to create a corpus of vocabulary used when training and act as vector representations of our text\n",
    "\n",
    "* Create the corpus of vocabulary which is used to train and evaluate throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = 100000  ## Only consider the top 20k words\n",
    "maxlen = 80  ## Max sequence length\n",
    "batch_size = 128  ## Data loading batch sizes\n",
    "\n",
    "# Create a dataset from the pandas column\n",
    "text_column = text_column.astype(str)  # Convert all elements to strings\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(text_column)\n",
    "\n",
    "# Shuffle and batch the dataset\n",
    "text_ds = text_ds.shuffle(buffer_size=128)\n",
    "text_ds = text_ds.batch(batch_size)\n",
    "\n",
    "# def custom_standardization(input_string):\n",
    "#     \"\"\" Remove html line-break tags and handle punctuation \"\"\"\n",
    "#     lowercased = tf.strings.lower(input_string)\n",
    "#     stripped_html = tf.strings.regex_replace(lowercased, \"<br />\", \" \")\n",
    "#     return tf.strings.regex_replace(stripped_html, f\"([{string.punctuation}])\", r\" \\1\")\n",
    "\n",
    "\n",
    "## Create a vectorization layer and adapt it to the text\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=None,\n",
    "    max_tokens=vocab_size - 1,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=maxlen + 1,\n",
    ")\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()  ## To get words back from token indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Labels\n",
    "\n",
    "Since we are building a generative auto-regressive model, we must train it to predict the next word by looking backwards and using the previous tokens to predict the highest probability for the next token.\n",
    "\n",
    "This is fairly easy to create labels for because we simply shuffle the `TRUE` data be one token and then when training the model compares the predicted text with the next indexed word.\n",
    "\n",
    "We can inspect what these samples and labels look like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function to create target column\n",
    "def prepare_lm_inputs_labels(text):\n",
    "    \"\"\"\n",
    "    Shift word sequences by 1 position so that the target for position (i) is\n",
    "    word at position (i+1). The model will use all words up till position (i)\n",
    "    to predict the next word.\n",
    "    \"\"\"\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "text_ds = text_ds.map(prepare_lm_inputs_labels)\n",
    "text_ds = text_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Input Sequence:\n",
      "\" I already gave you the source for all my edits The Slur database, so I will not continue to play your little game. If you weren't so lazy and intent on harassment, you could use Google to search for [UNK] and [UNK] You get more than 400 hits including white supremacist sites and an academic paper dating to 1996. It's obviously a real slur with some usage. Nice try at being obdurate though. I'm sure there's a slur that\n",
      "\n",
      "Target Sequence:\n",
      "I already gave you the source for all my edits The Slur database, so I will not continue to play your little game. If you weren't so lazy and intent on harassment, you could use Google to search for [UNK] and [UNK] You get more than 400 hits including white supremacist sites and an academic paper dating to 1996. It's obviously a real slur with some usage. Nice try at being obdurate though. I'm sure there's a slur that describes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Input Sequence:\n",
      "\" I'd say Zivo [UNK] is not heavy metal but hard rock, although since there are no good Croatian heavy metal bands it's not an important mistake. In my opinion, they are really fucking great. The songs [UNK] [UNK] \"\"Kill Yourself\"\" and [UNK] are my favourites. \"                                 \n",
      "\n",
      "Target Sequence:\n",
      "I'd say Zivo [UNK] is not heavy metal but hard rock, although since there are no good Croatian heavy metal bands it's not an important mistake. In my opinion, they are really fucking great. The songs [UNK] [UNK] \"\"Kill Yourself\"\" and [UNK] are my favourites. \"                                  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Input Sequence:\n",
      "3RR RULE That's FOUR for you today already at Saudi Arabia, Yuber. I'm assuming good faith and not going to report you on it yet. Knock it off.                                                    \n",
      "\n",
      "Target Sequence:\n",
      "RULE That's FOUR for you today already at Saudi Arabia, Yuber. I'm assuming good faith and not going to report you on it yet. Knock it off.                                                     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Input Sequence:\n",
      "I confess to having complete (and apparently blissful) ignorance of Jordan, but I've glanced at the article. Is this a woman or a soap opera!?. I don't think there was much to change in terms of the description of the various diseases. It is mentioned that she is famous for the size of her breasts: am I correct in assuming this is because they are grotesquely large rather than vanishingly small? [UNK] 11 Jul 2003 (UTC)    \n",
      "\n",
      "Target Sequence:\n",
      "confess to having complete (and apparently blissful) ignorance of Jordan, but I've glanced at the article. Is this a woman or a soap opera!?. I don't think there was much to change in terms of the description of the various diseases. It is mentioned that she is famous for the size of her breasts: am I correct in assuming this is because they are grotesquely large rather than vanishingly small? [UNK] 11 Jul 2003 (UTC)     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Input Sequence:\n",
      "Please just let us know what you found. I'm not asking for details. Just let u know if the same IP address was used or what ever else you found that caused you to determien that he was usign sockpuppets. No details, jsut what was it? I am one of Rob;s most hated enemies, so I think I'm the perfect person to ask this. Vandalism from an IP address used by Deskana was revealed using checkuser adn he was able\n",
      "\n",
      "Target Sequence:\n",
      "just let us know what you found. I'm not asking for details. Just let u know if the same IP address was used or what ever else you found that caused you to determien that he was usign sockpuppets. No details, jsut what was it? I am one of Rob;s most hated enemies, so I think I'm the perfect person to ask this. Vandalism from an IP address used by Deskana was revealed using checkuser adn he was able to\n"
     ]
    }
   ],
   "source": [
    "## Select samples from the training data set to inspect\n",
    "sample = text_ds.take(5) \n",
    "\n",
    "## Display some samples\n",
    "for x, y in sample:\n",
    "    # Convert token indices back to words\n",
    "    input_words  = [vocab[i] for i in x[0].numpy()]\n",
    "    target_words = [vocab[i] for i in y[0].numpy()]\n",
    "\n",
    "    print(\"\\n\\n\\n\\nInput Sequence:\")\n",
    "    print(\" \".join(input_words))\n",
    "    print(\"\\nTarget Sequence:\")\n",
    "    print(\" \".join(target_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***We can see that the target or label sequence is merely our ground truth text sequence we have just shifted by `1` token. This is what our model will use to evaluate during training.***\n",
    "\n",
    "* ***Cell below was for loading in and preprocessing the IMBD movie quotes dataset. This is the dataset I tested this approach on first.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the Transformer Block and Attention Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
    "    \"\"\"\n",
    "    Creates a mask for causal (auto-regressive) self-attention. The returned mask has the shape \n",
    "    [batch_size, n_dest, n_src], where each entry at position (i, j, k) will be 1 if j >= k and 0 otherwise. \n",
    "    This is used to prevent the attention mechanism from attending to future positions during the forward pass.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Number of sequences in each batch.\n",
    "        n_dest (int): Number of destination attention heads.\n",
    "        n_src (int): Number of source attention heads.\n",
    "        dtype (tf.DType): Type of the output tensor.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: A tensor of shape [batch_size, n_dest, n_src] representing the mask.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create two range tensors i and j, where i has shape [n_dest, 1] and j has shape [n_src]\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "\n",
    "    # Create a mask where entry (i, j) is True if i >= j - n_src + n_dest and False otherwise\n",
    "    m = i >= j - n_src + n_dest\n",
    "\n",
    "    # Cast the mask to the desired data type\n",
    "    mask = tf.cast(m, dtype)\n",
    "\n",
    "    # Reshape the mask to have shape [1, n_dest, n_src]\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "\n",
    "    # Create a tensor with shape [2] that represents the multiples for tiling\n",
    "    mult = tf.concat(\n",
    "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "    )\n",
    "\n",
    "    # Tile the mask tensor to have shape [batch_size, n_dest, n_src]\n",
    "    return tf.tile(mask, mult)\n",
    "\n",
    "\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    \"\"\"\n",
    "    A Transformer block that includes multi-head self-attention and a feed-forward neural network.\n",
    "    Each of these two components has a residual connection and is followed by layer normalization.\n",
    "\n",
    "    Attributes:\n",
    "        att (layers.MultiHeadAttention): Multi-head self-attention layer.\n",
    "        ffn (keras.Sequential): Feed-forward neural network.\n",
    "        layernorm1 (layers.LayerNormalization): Layer normalization after the self-attention.\n",
    "        layernorm2 (layers.LayerNormalization): Layer normalization after the feed-forward network.\n",
    "        dropout1 (layers.Dropout): Dropout layer after the self-attention.\n",
    "        dropout2 (layers.Dropout): Dropout layer after the feed-forward network.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1,**kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the Transformer block.\n",
    "\n",
    "        Args:\n",
    "            embed_dim (int): Dimensionality of the input embeddings.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            ff_dim (int): Number of units in the hidden layer of the feed-forward network.\n",
    "            rate (float): Dropout rate.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.att = layers.MultiHeadAttention(num_heads, embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the Transformer block.\n",
    "\n",
    "        Args:\n",
    "            inputs (tf.Tensor): Input tensor of shape [batch_size, seq_len, embed_dim].\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Output tensor of shape [batch_size, seq_len, embed_dim].\n",
    "        \"\"\"\n",
    "        # Compute the shapes\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "\n",
    "        # Create the causal mask for the multi-head self-attention\n",
    "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "\n",
    "        # Compute the output of the multi-head self-attention\n",
    "        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n",
    "\n",
    "        # Apply dropout to the attention output\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "\n",
    "        # Add the attention output to the inputs (residual connection) and normalize the result\n",
    "        out1 = self.layernorm1(inputs + attention_output)\n",
    "\n",
    "        # Compute the output of the feed-forward network\n",
    "        ffn_output = self.ffn(out1)\n",
    "\n",
    "        # Apply dropout to the feed-forward output\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "\n",
    "        # Add the feed-forward output to the previous output (residual connection) and normalize the result\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self): # 5\n",
    "        config = super().get_config()\n",
    "        # save constructor args\n",
    "        config['embed_dim'] = self.embed_dim\n",
    "        config['num_heads'] = self.num_heads\n",
    "        config['ff_dim'] = self.ff_dim\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Embedding layer\n",
    "\n",
    "***Create two separate embedding layers:***\n",
    "\n",
    "1) One for tokens \n",
    "\n",
    "2) One for token indices(positions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    \"\"\"\n",
    "    Layer for combining token and positional embeddings. Token embeddings provide the model\n",
    "    with understanding of the meaning of each token, while positional embeddings provide\n",
    "    information about the position of each token in the sequence.\n",
    "\n",
    "    Attributes:\n",
    "        token_emb (layers.Embedding): Token embedding layer.\n",
    "        pos_emb (layers.Embedding): Position embedding layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, name=None, **kwargs):\n",
    "        super(TokenAndPositionEmbedding, self).__init__(**kwargs)\n",
    "        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "        \n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the TokenAndPositionEmbedding layer.\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): Input tensor of shape [batch_size, seq_len].\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Output tensor of shape [batch_size, seq_len, embed_dim], resulting from\n",
    "            adding token embeddings and position embeddings.\n",
    "        \"\"\"\n",
    "        # Compute the maximum sequence length\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "\n",
    "        # Create a range tensor representing positions\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "\n",
    "        # Compute the position embeddings\n",
    "        positions = self.pos_emb(positions)\n",
    "\n",
    "        # Compute the token embeddings\n",
    "        x = self.token_emb(x)\n",
    "\n",
    "        # Add the token embeddings and position embeddings\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self): # 5\n",
    "        config = super().get_config()\n",
    "        # save constructor args\n",
    "        config['maxlen'] = self.maxlen\n",
    "        config['vocab_size'] = self.vocab_size\n",
    "        config['embed_dim'] = self.embed_dim\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the Mini GPT\n",
    "\n",
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocab_size = 30000  # Only consider the top 20k words\n",
    "maxlen = 80  # Max sequence size\n",
    "embed_dim = 256  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "feed_forward_dim = 256  # Hidden layer size in feed forward network inside transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow_addons.optimizers import AdamW\n",
    "def MiniGPT():\n",
    "    \"\"\"\n",
    "    Constructs a mini version of the GPT model. The architecture is comprised of a\n",
    "    token and position embedding layer followed by a single Transformer block. The final\n",
    "    layer is a dense layer with softmax activation for prediction. \n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Mini GPT model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input layer expects inputs of shape (maxlen,) with type int32\n",
    "    inputs = layers.Input(shape=(maxlen,), dtype=tf.int32)\n",
    "\n",
    "    # Create the token and position embedding layer and compute the embeddings\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "\n",
    "    # Create the Transformer block and compute its output\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n",
    "    x = transformer_block(x)\n",
    "\n",
    "    # Final dense layer with size equal to the vocabulary size\n",
    "    outputs = layers.Dense(vocab_size)(x)\n",
    "\n",
    "    # Construct the Keras model\n",
    "    model = keras.Model(inputs=inputs, outputs=[outputs, x])\n",
    "\n",
    "    # Loss function for the training \n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Model compilation: use Adam optimizer and the defined loss function\n",
    "    # Note that we specify `None` for the second loss to not optimize based on the Transformer block's output\n",
    "    model.compile(\"adam\", loss=[loss_fn, None])\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {
    "a896bbaf-c33d-4700-b0b2-dc7aabd2e598.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "***Shout out to this amazing app: https://netron.app/***\n",
    "***You simply drag and drop your tensorflow or pytorch model into the app and it generates the diagram for you!***\n",
    "\n",
    "![Screen Shot 2023-06-25 at 6.55.38 PM.png](attachment:a896bbaf-c33d-4700-b0b2-dc7aabd2e598.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Text Generator Callback Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextGenerator(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A callback to generate text from a trained model at the end of each epoch. It uses the model's \n",
    "    predictions to sample a token, add it to the input, and generate subsequent tokens.\n",
    "\n",
    "    Attributes:\n",
    "        max_tokens (int): The number of tokens to be generated after the prompt.\n",
    "        start_tokens (list): The token indices for the starting prompt.\n",
    "        index_to_word (list): Mapping from token indices to words, obtained from the TextVectorization layer.\n",
    "        k (int): Number of token predictions to consider for sampling the next token.\n",
    "        print_every (int): Frequency of print for the generated text (in number of epochs).\n",
    "    \"\"\"\n",
    "    def __init__(self, max_tokens, start_tokens, index_to_word, top_k=20, print_every=1,**kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the TextGenerator callback.\n",
    "\n",
    "        Args:\n",
    "            max_tokens (int): Maximum number of tokens to be generated.\n",
    "            start_tokens (list): List of integers representing the starting tokens.\n",
    "            index_to_word (list): List of strings representing the mapping from indices to words.\n",
    "            top_k (int, optional): Number of top token predictions to sample from. Defaults to 10.\n",
    "            print_every (int, optional): Frequency of print (in number of epochs). Defaults to 1.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.max_tokens = max_tokens\n",
    "        self.start_tokens = start_tokens\n",
    "        self.index_to_word = index_to_word\n",
    "        self.k = top_k\n",
    "        self.print_every = print_every\n",
    "        self.generated_texts = [] # for qualitative validation set\n",
    "\n",
    "    def sample_from(self, logits):\n",
    "        \"\"\"\n",
    "        Sample a token index from the token predictions based on their probabilities.\n",
    "\n",
    "        Args:\n",
    "            logits (tf.Tensor): The token predictions (logits) of the model.\n",
    "\n",
    "        Returns:\n",
    "            int: The sampled token index.\n",
    "        \"\"\"\n",
    "        # Select top-k logits and their indices\n",
    "        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n",
    "        indices = np.asarray(indices).astype(\"int32\")\n",
    "\n",
    "        # Apply softmax to transform logits into probabilities\n",
    "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
    "        preds = np.asarray(preds).astype(\"float32\")\n",
    "\n",
    "        # Randomly select an index according to the probability distribution\n",
    "        return np.random.choice(indices, p=preds)\n",
    "\n",
    "    def detokenize(self, number):\n",
    "        \"\"\"\n",
    "        Convert a token index into the corresponding word.\n",
    "\n",
    "        Args:\n",
    "            number (int): The token index.\n",
    "\n",
    "        Returns:\n",
    "            str: The corresponding word.\n",
    "        \"\"\"\n",
    "        return self.index_to_word[number]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        At the end of each epoch, generate text and print it.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The current epoch number.\n",
    "            logs (dict, optional): Dictionary of metrics from the epoch. Defaults to None.\n",
    "        \"\"\"\n",
    "        # Create a copy of start tokens for generation\n",
    "        start_tokens = [_ for _ in self.start_tokens]\n",
    "\n",
    "        # Only generate text at specified frequency\n",
    "        if (epoch + 1) % self.print_every != 0:\n",
    "            return\n",
    "\n",
    "        num_tokens_generated = 0\n",
    "        tokens_generated = []\n",
    "\n",
    "        # Generate tokens until max tokens reached\n",
    "        while num_tokens_generated <= self.max_tokens:\n",
    "            pad_len = maxlen - len(start_tokens)\n",
    "            sample_index = len(start_tokens) - 1\n",
    "\n",
    "            # Adjust padding based on length of start tokens\n",
    "            if pad_len < 0:\n",
    "                x = start_tokens[:maxlen]\n",
    "                sample_index = maxlen - 1\n",
    "            elif pad_len > 0:\n",
    "                x = start_tokens + [0] * pad_len\n",
    "            else:\n",
    "                x = start_tokens\n",
    "\n",
    "            x = np.array([x])\n",
    "\n",
    "            # Use the model to predict the probabilities for the next token\n",
    "            y, _ = self.model.predict(x)\n",
    "\n",
    "            # Sample a token from the model's output distribution\n",
    "            sample_token = self.sample_from(y[0][sample_index])\n",
    "\n",
    "            # Append the token to the list of generated tokens\n",
    "            tokens_generated.append(sample_token)\n",
    "\n",
    "            # Add the token to the start tokens for the next generation\n",
    "            start_tokens.append(sample_token)\n",
    "\n",
    "            # Increase the number of tokens generated by 1\n",
    "            num_tokens_generated = len(tokens_generated)\n",
    "\n",
    "        # Convert the tokens into actual words and join them into a string\n",
    "        txt = \" \".join(\n",
    "            [self.detokenize(_) for _ in self.start_tokens + tokens_generated]\n",
    "        )\n",
    "        \n",
    "        self.generated_texts.append((epoch, txt)) # Store for evalutation after training\n",
    "\n",
    "\n",
    "        # Print the generated text\n",
    "        print(f\"generated text:\\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word/Index Mapping Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Tokenize starting prompt\n",
    "word_to_index = {}\n",
    "for index, word in enumerate(vocab):\n",
    "    word_to_index[word] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Callback Object\n",
    "\n",
    "***We also need to supply a starting prompt to act as a qualitative validation set to evaluate the models performance from a 'does it make more sense' per epoch. It will generate(predict) a text sequence continuation from the starting prompt at the end of every epoch to inspect.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_prompt = \"I would have\"\n",
    "\n",
    "start_tokens = [word_to_index.get(_, 1) for _ in start_prompt.split()]\n",
    "num_tokens_generated = 42\n",
    "text_gen_callback = TextGenerator(num_tokens_generated, start_tokens, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "***I apologize for the scrolling your about to do. I wanted to generate text at each epoch so that along with loss there would be some qualitative evaluation on the models performance throughout training but I could not find a way to remove the progress bars for each step inside the epochs... If anyone reading this knows a way please comment.***\n",
    "\n",
    "***Until about `25` epochs many of the generations depending on the satrting prompt during training had nonsensical outputs. So we will use `25` to get a good baseline model to evaluate.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 80)]              0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, 80, 256)          25620480  \n",
      " g_11 (TokenAndPositionEmbed                                     \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " transformer_block_7 (Transf  (None, 80, 256)          658688    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 80, 100000)        25700000  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,979,168\n",
      "Trainable params: 51,979,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 223ms/step loss: 4.7191 - dense_23_loss: 4.71\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "generated text:\n",
      "I would have a single guy in the State who should be a lot of the state in order for a lot of my time and the state and then it was not a lot of the [UNK] The same way out of course of the\n",
      "\n",
      "168/168 [==============================] - 39s 216ms/step - loss: 4.7191 - dense_23_loss: 4.7191\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 17ms/step- loss: 3.4660 - dense_23_loss: 3.46\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "generated text:\n",
      "I would have to understand how many times like you. How is the oil and that is a great man like this is about the world from the rest of an article that it was the only the time and a problem is a person that\n",
      "\n",
      "168/168 [==============================] - 36s 214ms/step - loss: 3.4660 - dense_23_loss: 3.4660\n"
     ]
    }
   ],
   "source": [
    "model = MiniGPT()\n",
    "\n",
    "N_EPOCHS = 2\n",
    "history  = model.fit(text_ds, verbose=1, epochs=N_EPOCHS, callbacks=[text_gen_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Training Loss Per Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Validation Set Per Epoch\n",
    "\n",
    "***Since we don't have a quantitative validation set in this situation we can use a qualitative validation set. These would be the generated text from the end of each epoch. This can give us some clues along with the losses per epoch to see how the models performance progressed through training.***\n",
    "\n",
    "***Lets inspect what the first five generations look llike compared to the last five during training.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Generated Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I would have a single guy in the State who sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I would have to understand how many times like...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch                                     Generated Text\n",
       "0      0  I would have a single guy in the State who sho...\n",
       "1      1  I would have to understand how many times like..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Generated Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I would have a single guy in the State who sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I would have to understand how many times like...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch                                     Generated Text\n",
       "0      0  I would have a single guy in the State who sho...\n",
       "1      1  I would have to understand how many times like..."
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for epoch, text in text_gen_callback.generated_texts:\n",
    "#     print(f\"Epoch: {epoch+1}\\nGenerated Text:\\n{text}\\n\")\n",
    "    # Create a DataFrame\n",
    "    \n",
    "df_val = pd.DataFrame(text_gen_callback.generated_texts, columns=['Epoch', 'Generated Text'])\n",
    "\n",
    "display(df_val.head(5));df_val.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***It appears to that with more iterations the model becomes more and more realistic in its generations. The model starts producing less unknown tokens over time during training iterations.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "***Now that we have trained the model to generate toxic comments from a starting prompt we can begin to generate our synthetic data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(starting_prompt=''):\n",
    "    new_start_prompt = \"here we\"\n",
    "    new_start_tokens = [word_to_index.get(word, 1) for word in new_start_prompt.split()]\n",
    "\n",
    "    text_gen_callback.start_tokens = new_start_tokens\n",
    "    text_gen_callback.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "generated text:\n",
      "here we should be all these taxes or [UNK] or more than one should have a person for their noses and that if the most money for the world have an insult the State and the oil companies that is so they are a good\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_text(\"you are\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## State of training data\n",
    "\n",
    "* I learned alot on this project. It is interesting to me that with all of the data in the world there is still a shortage of industrial sized, cleaned, organized, and labeled training data. \n",
    "\n",
    "* It would seem that allthough in academia the glory goes to the next new model or algorithm when really the training data is probably more important at this point. It does not matter how fancy an algorithm is(some of them are pretty fancy) or a model is, without good training data we are limited in the problems we can tackle effectively.\n",
    "\n",
    "* During this project I researched training data sets and where they come from. Most of the open source ones come from a handful of instituions namely universities with a few corporations willing to share the training datasets or models which would not effect their market share significantly releasing them.\n",
    "\n",
    "* Even the sensitive subjetcs such as the language used in this projects training data is very important to solve very prominent problems we have.\n",
    "\n",
    "## Decisions made along the way\n",
    "* I started off this project trying to adapt a GAN to acheive this tast but there is little work done in this area and I had a lot of trouble trying to implement one of the papers where they achieve this task.\n",
    "\n",
    "* I chose this method as this model is lightweight and quick to train and tune for any specific style of language. As I mentioned at the beginning I originally tested this capabillity on the movie lines IMDB dataset and had great results. \n",
    "\n",
    "* The dataset I used turned out to be admittedly smaller than probably needed to get better results but I am confident that once I wrange up more nasty online comments the model will do much better after retraining.\n",
    "\n",
    "* The feature dimensions in the attention head made a huge difference on training time and performance. I had better results at 512 than it is currently at (256) but the time to train 25 epochs grew exponentially. If I had more Kaggle GPU hours I would have done my final training round with 512 in the attention head.\n",
    "\n",
    "* I originally tried a custom learning rate optimizing function but because of the large differences in epochs I was trying for different experiments I switched over to just using ADAM for this task.\n",
    "\n",
    "* The starting prompt matters. I found out that after looking at the popular bigrams and trigrams if I chose those sequences the model would generate sensible text more easily. \n",
    "\n",
    "* The length of the starting prompt also effects how different each output is dramatically.\n",
    "\n",
    "## Whats Next\n",
    "\n",
    "* I am going to run this model and compile a set of generated texts which are known to be toxic and add them to the training set and retrain the BERT based model I used when competing in this competition to see what results I get with the added training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Toxic_MiniGPT1.keras')\n",
    "\n",
    "\n",
    "with tf.keras.utils.custom_object_scope({\n",
    "    'TransformerBlock': TransformerBlock,\n",
    "    'TokenAndPositionEmbedding': TokenAndPositionEmbedding\n",
    "}):\n",
    "    loaded_model = tf.keras.models.load_model('Toxic_MiniGPT1.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the vocab\n",
    "file_path = 'vocab.txt'\n",
    "\n",
    "# Write each word from the vocab array to the file\n",
    "with open(file_path, 'w') as file:\n",
    "    for word in vocab:\n",
    "        file.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'vocab.txt'\n",
    "\n",
    "# Read each line from the file and append it to the vocab list\n",
    "loaded_vocab = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        loaded_vocab.append(line.strip())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
